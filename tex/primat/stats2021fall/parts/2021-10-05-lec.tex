\documentclass[main.tex]{subfiles}
\begin{document}
	
	\section{Проверка статистических гипотез. Продолжение}
	В прошлый раз рассмотрели задачу про бактерии в воде.
	\subsubsection{Параметрический критерий отношения правдоподобия}
	
Подразумевается, что параметрическое множество -- подмножество евклидова пространства $ \mathds R ^k $ (иногда, впрочем, некоторые параметры положительные).
Гипотеза $ H_0 $: вектор параметров лежит в подпространстве меньшей размерности (т.е. какие-то из параметров равны нулю).
В качестве альтернативы можно либо просто предположить невыполнение $ H_0 $.
Если же хотим контролировать ошибку $ 2 $ рода, фиксируем какую-то альтернативу.

Возможна также \emph{меняющаяся} (стягивающаяся) альтернатива: $ \Theta_A = \Theta_{A,n} \subset \mathds R^k : dist(\Theta_0, \Theta_{A,n}) $ (не один эксперимент, а последовательность стягивающихся).

Какие распределения можно использовать?
Обычно дискретные или непрерывные, редко -- смешанные (но тогда придумываем доминирующую меру).

Статистика \textbf{отношения правдоподобия}:

\[ \lambda_n = LR(X, \Theta_0, \Theta) = \frac{\sup_{\vartheta \in \Theta_0}L(X,\vartheta)}{\sup_{\vartheta \in \Theta} (X, \vartheta)} \]

Основное утверждение -- \textbf{теорема Уилкса}:

\begin{leftbar} % TODO theorem?
Пусть выполнен ряд условий регулярности эксперимента; пусть множество, соответствующее нулевой гипотезе -- подпространство размерности $ d $, вложенное в пространство всех параметров  размерности $ k $.

Тогда $ \forall \theta \in \Theta_0 $ распределение статистики отношения правдоподобия стремится к распределению $ \chi^2_{k-d} $
\end{leftbar}

Во многих случаях удаётся доказать, что критерий является наиболее мощным (и даже равномерно наиболее общим!), но асимптотически (поскольку критерий асимптотический).

Проблема: когда параметр на границе, критерий теряет корректность.
Учтите это при разработке своих критериев!

Задача проверки значимости ставится как обычно: берётся параметр $ \theta = \begin{pmatrix}
	\theta_1 & \dots & \theta_k
\end{pmatrix} \in \mathds R^k $ -- $ d $-мерный параметр;

% TODO a bit

Предельное распределение -- $ \chi^2 $, т.о. получаем асимптотический нерандомизованный критерий.

Можем построить соответствующий критерий, исходя из выборки параметрического нормального распределения.
Конечно, для нормального распределения есть и точные критерии, просто проверим...

% TODO a bit

Максимум в данном случае берётся при фиксированном значении $ \theta_0 $, максимизируем по $\sigma^2$.
Похоже на оценку МП без ограничений, только вместо $X'$ у нас $ \theta_0 $.
Когда всё приводим и подставляем в функцию правдоподобия, получаем выражение $ n \ln \left(\frac{s_0^2}{s^2}\right) $.

Фактически получаем квадрат статистики Стьюдента.
Т.о. при больших $ n $ получаем, что статистика правдоподобия есть статистика Стьюдента.

\section{Новые слайды после перерыва. Интерпретация множества статистических тестов}

В своё время доказательная медицина строилась на проведении определённого теста.
Если $p-value$ было меньше определённого значения, можно было публиковаться.

Оказалось, что многие результаты экспериментов не воспроизводятся.
Люди обратили внимание на феномен...

\subsection{Множественное тестирование. Постановка задачи}

Гипотезы могут быть разные в одном статистическом эксперименте.
Каждой гипотезе соответствует критерий уровня значимости $\alpha$; в рамках одного эксперимента могут быть разные критерии, несколько наборов данных...

Ключевой вопрос: каждая гипотеза может быть ошибочно отвергнута с вероятностью $ \alpha $; если проверяем несколько гипотез, часть будут отвергнуты с большой вероятностью. Вероятность неверного отвержения иногда не представляется возможным из-за отсутствия независимости. Например, на одних данных использовали два критерия, один показал значимость, другой не показал -- и как это интерпретировать?

\subsection{К истокам}

Пример.
Во времена <<произвола доказательной медицины>> молодой психолог провёл тесты (250) и нашёл 11 значимых отклонений от независимости с $ 5\% $ уровнем значимости.
Опытный статистик (Тьюки) отметил, что ожидаемое число тестов, которые ошибочно покажут зависимость, $ 12.5 $ из $ 250 $ даже при независимых экспериментах.

В современной науке иногда просто выводят $p$-значения, не говоря о том, значимые ли отклонения.

В полногеномном поиске ассоциаций число $250$ заменяется на миллионы генетических маркеров (и миллионы тестов!).
Конечно, перед исследованием проводится QC...
но нужно перед проведением эксперимента оценить мощность (будет ли критерий давать правдоподобные результаты хотя бы при наличии сильной зависимости).

Ещё одно замечание: мало кому интересно публиковать неподтверждённые результаты.
Если человек провёл эксперимент, ничего не нашлось и не опубликовали, потом другой провёл аналогичный эксперимент и не нашлось... а потом у кого-то нашлось (и только он опубликовал статью!), то потом эти результаты, вероятно, не удастся опубликовать.

Сейчас до сих пор результаты публикации в большом числе случаев воспроизвести не удаётся.

Пример настоящего исследования: при нашем прошлом главе лаборатории (Стефан О. Брайен) статистическими методами нашли делецию, которая деактивирует рецептор в клетке, который использует для проникновения вирус ВИЧ (заболеваемость ВИЧ в группе людей с этой делецией гораздо ниже, чем у остальных).
Потом оказалось, что есть ещё один рецептор, через который (правдо, гораздо реже) может проникать вирус.
Это настоящее исследование!

Но наверное я бы всё-таки не относился так серьёзно к выводам, полученным статистическим путём и не подтверждённым какими-то другими методами.

% TODO a bit

Пока не говорили о поправке, об этом позже...
но понятно, что на таком уровне могут возникать какие угодно эффекты.

% TODO a bit

Проблемы интерпретации результатов множества тестов близки к задачам идентификации сигнала.
Чем больше экспериментов проводится, тем труднее найти сигналы, которые гарантированно будут соответствовать связи сопутствующих признаков с наблюдаемыми.
Т.о., если проводится достаточно много исследований, эффективность метода падает для каждой гипотезы.
Но если сигнал всё же достаточно сильный и выборка большая, удаётся несколько зависимостей установить.

\subsection{ Контроль ошибок множественного тестирования}

\subsubsection{FWER}

Пусть имеется $ N $ статистических тестов.
Можно построить таблицу сопряжённости (для всех результатов)

\[ \begin{pmatrix}
	\text{} & \text{вероятность ошибки I рода} \\
	\text{вероятность ошибки II рода} & \text{} \\
\end{pmatrix} =
\begin{pmatrix}
	N_{00} & N_{10} \\
	N_{01} & N_{11} \\
\end{pmatrix} \]

Вероятность наличия хотя бы одного ошибочного сигнала -- \emph{Family Wise Error rate} (FWER) $ = \mathds P (N_{10} > 0) $.

\subsubsection{Benjamini \& Hochberg}

Иной подход, который развивался раньше, но принято считать, что он разработан Беньямини и Хохбергом:  FDR -- число ошибочно выбранных сигналов к общему (не гарантируем, что все решения корректны при выбранном уровне значимости, но считаем, что оно достаточно мало при установленном пороге).

\[ FDR \overset{def} = \frac{\mathds E (N_{10})}{ N_{10} + N_{11} } \]

Первое -- более жёсткий контроль.
Но зато FDR позволяет иногда не выбрасывать некоторую полезную статистическую информацию.

Можно считать, что, если ничего не выбрано, то ничего и корректировать не надо.
А можно % TODO a bit

\subsection{Задача бинарной классификации}

Выбор между ошибкой или не ошибкой можно считать задачей бинарной классификации.
Т.о. можно определить TPR, FPR и построить ROC-кривую.
В качестве числового показателя качества бинарного классификатора часто используют площадь под кривой (AUC).

\subsection{Поправки множественного тестирования}

Контроль ошибки 1 рода (Family Wise Error Rate): основано на неравенстве Буля (это одно из первых неравенств, которые мы проходим в теории вероятностей -- вероятность объединения не превышает вероятности событий).

\[ \mathds P \left( \cup_{i=1}^N A_i \right) \le \sum_{i=1}^N \mathds P (A_i) \quad \forall \{ A_i \}_{i=1}^N \]

С этой поправкой тесно связана поправка Дана и Шидака.
Она не может быть улчшена (ведь не неравенство, а равенство).
При большом $ N $ и малом $ \alpha $, впрочем, 

\end{document}
