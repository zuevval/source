\documentclass[main.tex]{subfiles}
\begin{document}
	
\section{Множественное тестирование. Продолжение}

Метод Хольма (Holm, 1979) -- пошаговый: утверждается, что разумно расположить найденные p-значения в порядке убывания ($ P_{(1)} \le ... \le P_{(N)} $) и выбирать все тесты, для которых на каком-то шаге $ P_{(i)} < \frac{\alpha}{N - i + 1} $.
Идём по шагам и останавливаемся, когда условие перестаёт выполняться.

Ещё один метод, который работает, когда проводится очень много тестов и существенная их часть может влиять на результат: за счёт изменения подхода к измерению ошибки увеличиваем число взятых тестов.
Здесь мы ограничиваем не вероятность ошибки I рода, а FDR.
Классический метод такого рода -- Беньямини-Хохберга:
Можем контролировать FDR на уровне $ m_0 $.
Впрочем, мы  $ m_0 $ не знаем.

Когда проводятся генетические исследования, довольно часто имеет смысл рассматривать подход, основанный на FDR (все факторы, влияющие на результат, всё равно не удастся выявить; так давайте выявим их побольше).

Недостаток метода Беньямини-Хохберга: % TODO a bit

Положительная зависимость...

Если выбирать тесты, для которых $ P_{(i)} < \left( \frac{i \sum }{} \right) $ % TODO
В более общем случае можно вывести более слабый результат.

\subsubsection{Оценка числа сигналов}

Есть некое отношение числа сигналов $m_0$ к общему числу тестов $n$.
Если бы мы заранее знали это отношение, смогли бы более эффективно находить ложные сигналы.
Заранее не зная $m_0$,  предполагаем худший случай: $ m_0 = n $.
Но иногда мы наверняка знаем, что какое-то количество сигналов есть.

Подход, в какой-то степени байесовский: обозначаем $ \pi_0 := m_0 / N $; считаем, что это случайная величина.
Посмотрим на распределение  $p$-значений.
$p$-значение -- отнормированная статистика % (?)

Как оценить $\pi_0$?
Априорное распределние $p$-значений могли бы заменить на наблюдаемое.
На практике обычно используется оценка $ \hat \pi_0(\lambda) = \frac{num}{den} $ % TODO formula from the slide

Более строгий подход: Сторей (Storey, 2002)
\[ FDR(\gamma) = E(N_{10}(\gamma)/R(\gamma)) \approx EN_{10}(\gamma) / ER(\gamma) \]
здесь $ N_{10} $ -- число ошибок первого рода при $ P_{(i)} \le \gamma $, $ R(\gamma) $ -- число $ P_i : P_i \le \gamma $.
Идея метода -- контроль $ FDR(P_{(i)}) $ вместо FDR.

Утверждается, что асимптотически этот метод...


\subsubsection{Зависимые результаты}

Независимые результаты с точки зрения возможностей поправок -- один из худших вариантов.
% TODO
Поправка Данна-Шидака...

Если статистики критериев сильно коррелируют -- как быть?
Как можно улучшить критерии?

\begin{enumerate}
	\item  Первый подход к улучшению критериев -- \emph{перестановочный}.
	При основной гипотезе от перемены точек значение
\end{enumerate}

% TODO missed many; генетические маркеры
Linkage Disequilibrium
Появляется возможность каким-то образом ограничить и сделать число ошибок менее зависимым от числа тестов.
С другой стороны, никто это $N_{\text{эффективное}}$ учитывать не умеет. \\

Есть подходы, не связанные с перестановками.
Иногда статистику можно представить как функцию от асимптотически нормальных величин.
В общем случае решение такой задачи неизвестно, но при определённом виде ковариационной матрицы можно...

Кроме метода Монте-Карло --  \emph{метод Москвиной и Шмидта} (2008).
Впрочем, доказательства у него нет.
С точки зрения гипотезы о нормальном распределении предположение выглядит естественным.

\subsection{ Проблема множественного тестирования. Заключение }

Если делаем два разных теста (или более), надо либо смотреть на оба, либо делать поправки.

Можно так: делаем тест хи-квадрат, считаем его базовым; если приняли гипотезу (тест что-то показал), смотрим дополнительно на другие тесты.
Каждый тест заточен на определённую альтернативу.
Если заранее не знаем альтернативу, хорошо бы сделать несколько тестов.

Ещё раз, возможна такая идеология: ищем сигнал общим тестом, потом уточняем следующим тестом, который заточен на конкретную альтернативу.
Это статистически корректно.

Важно помнить, что надо заранее стандартизировать процесс принятия решений.

В классическом подходе: не можем проверить все факторы, но можем проверить, насколько группы по основному фактору сбалансированы по дополнительному фактору.

Статистика теоретическая, на самом деле, более простая, чем статистика прикладная...
В теоретической статистике всё определяется формулами!

\end{document}