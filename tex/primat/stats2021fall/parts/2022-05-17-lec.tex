\documentclass[main.tex]{sufbfiles}
\begin{document}
	
\section{ Подготовка данных для GWAS. Продолжение 2 }
May 17, 2022
\subsection{ Родственные связи }
\textbf{identity by descent}: две аллели называются  \textit{ идентичными по происхождению }, если они оба были получены из одной аллели общего предка.

Идентичные по происхождению аллели совпадают, но не совпадающие аллели идентичны по происхождению.

У нас есть текущая популяция.
Рассмотрим двух производных индивидов из этой популяции.

Вверху: две аллели индивида А, внизу -- две аллели индивида B.
Аллели одинаковых цветов совпадают.
Идентичными по происхождению являются только те аллели, которые соединены рёбрами.
Если популяция без инбридинга, возможны только вертикальные рёбра.

Коэффициент Галуа-Жаккарда

\[ \Phi_{AB} = \Delta_1 + \frac{1}{2} \left( \Delta_3 + \Delta_5 + \Delta_7 \right) + \frac{1}{4} \Delta_8 \]

Вычисление коэффициента родства с использованием длин путей до общих предков:

В популяции без имбридинга $ \Delta_7 + \Delta_8 + \Delta_9 = 1 $.

\begin{tabular}{ccccc}
	Родственная связь & $ \Delta_7 $ & $ \Delta_8 $ & $ \Delta_8 $ & $ ?TODO$ \\
	\hline
	Клоны/близнецы (о.я.) & 1 & 0 & 0 & 1/2  \\
\end{tabular}


% TODO some

Коэффициент инбридинга $ f_C \overset{def}\leftrightarrow $  вероятность того, что обе аллели в случайно выбранном локусе IBD.
Вычисляется как $ f_C = \Phi_{AB} $

Внутренной коэффициент родства $ \Phi_{CC} = (1 + f_C)/2 $.
Поскольку маркеров много, родство определяется достаточно точно, хотя модель грубая.

Что делают с найденными родственниками?
Либо оставляют из родственников одного -- наиболее качественного, либо вводят поправку.
Как правило, поправка -- случайный эффект.

\section{ Поиск генетических ассоциаций }
Тоже 17 мая 2022 года.

Мы говорим о статистическом подходе.
Есть подход с использованием машинного обучения.

По-хорошему подход с МО в чистом виде не может считаться статистическим.
Подобные методы не дают в чистом виде ответ, проявляется ли признак в данной фиксированной популяции или может быть обобщён на произвольную популяцию.

Поговорим о классическом статистическом подходе.
Зависимость (статистическую) фенотипа от всего набора генетических маркеров не представляется возможным установить, поскольку число параметров в модели слишком велико: какого бы размера популяцию мы не взяли, не будет двух одинаковых индивидов.

Но если найти небольшой набор маркеров, (предположительно) ответственных за вариацию, можно построить модель.

В качестве маркеров могут выступать ОНП, вставки, делеции и так далее.

\subsection{ Статистический подход в задаче поиска ассоциаций }

LASSO, Ridge Regression, Elastic Nets

Классическая постановка: для каждого маркера выдвигают нулевую гипотезу о независимости $ H_0 $ и альтернативу $ H_A $, одинаковые для каждого маркера.
Используется, как правило, один статистический критерий.

Есть проблема с тестами: когда математическая модель эксперимента не вполне соответствует реальной ситуации, это может сказываться на P-значениях (они могут быть, в частности, сильно заниженными).
Если, например, преполагаем нормальность, а наблюдаемая величина, скажем, экспрессия, то выводы сомнительные.

\subsection{ Связь с задачами распознавания сигналов }

Интерпретация результатов множества тестов похожа на задачу 
Неизвестно, сколько сигналов (может не быть вовсе), где они.

\subsection{ Генотипы, альтернативы }

% TODO some

Когда генетические ассоциации найдены (получилось очень маленькое P-значение), останавливаться не нужно, а нужно посмотреть, насколько эта ассоциация сильная.
Силу ассоциации определяет отношение шансов.
Но стоит помнить, что надо рассматривать внешне
Для таблиц $ 2 \times 2 $ удобно использовать $ T^{1/2} = log(OR)/\sqrt V $.
Это можно использовать для доминантного или аллельного подхода.
Коэффициент корреляции, по большому счёту, не определяет зависимость, но в кодоминантном подходе для бинарной переменной такой подход может быть использован.
Можно также использовать GLM

\subsection{ Интерпретация результатов множественных тестов }

Базовый метод -- Бонферрони.
Намного улучшить этот метод, но при большом количестве маркеров поправка получается слишком строгая: при $ n = 10^6 $, хотим уровень значимости $ 5\% \Rightarrow $

\subsubsection{Ошибки множественного тестирования}

Напомним: та же табличка, что и в классической статистике; контролируем FWER (Family wise error rate, ошибка первого рода) или FDR (False discovery rate).

Метод Хольма -- модифицированный метод Бонферрони: упорядочиваем P-value в порядке возрастания ($ P_{(1)} \le \dots \le P_{(N)} $); выбираем все тесты с наименьшими $ P $-значениями.

Контроль FDR: есть метод Берьямини-Хочберга.
Правда, он предполагает независимость тестов.
Для произвольных тестов 


\end{document}