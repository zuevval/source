\subsection{Процедура Хатчинсона}

Пусть $ B \in \mathds{R}^{n\times n} $ -- симметричная матрица и $ tr(B) \ne 0 $.
Пусть также $ u \in \{-1, 1\}^n $ -- вектор-столбец единиц со случайным знаком, причём знаки равновероятны. Тогда $ \mathds{E} (u^T B u) = tr(B) $ \cite{golub2010matMomentsQuadr}.

Следовательно, след матрицы можно оценить, сгенерировав случайным образом $ p $ векторов $ u_k, k \in \{1;p\} $ и вычислив затем выражение следующего вида:
\begin{equation}\label{eq:hutch}
    \overline{tr(B)} = \frac{1}{p} \sum_{k=1}^p u_k^T B u_k
\end{equation}

Безусловно, способ \eqref{eq:hutch} имеет смысл только при $ p \ll n $ и только в том случае, если известен некоторый быстрый способ вычисления билинейной формы $ u_k^T B u_k $ (быстрый по сравнению с прямым перемножением), иначе выигрыша в скорости работы не будет.
Далее обсуждается метод приближённой оценки билинейной формы в случае $ B = f(A) $, иными словами, когда $B$ есть функция от другой квадратной матрицы.

\subsection{Билинейная форма как интеграл Римана-Стилтьеса}\label{section:stieltjes}

Пусть дан промежуток $ [a;b] $, и некоторая \emph{весовая функция} $ w(x) $ монотонна и непрерывна справа на $ [a;b] $, а функция $f(x): \mathds{R}\to \mathds{R}$ интегрируема на $ [w(a);w(b)] $.
Рассмотрим интеграл Римана-Стильтеса

\begin{gather}
    \label{eq:stieltjes}
    I(f) \equiv \int_{a}^{b} f(x) dw(x) \defeq \lim_{\lambda \to 0} S_m \\
    \label{eq:stieltjesSum}
    \space S_m = \sum_{k=0}^{m-1} f(c_k) (w(x_{k+1}-w(x_k))), c_k \in [x_k; x_{k+1}]
\end{gather}
где $\lambda$ -- ранг дробления, $m$ -- число точек в разбиении.

Зададим $ w(x) $ как ступенчатую функцию с узлами $ \lambda_k \in [a;b], k \in \{1;n\} $.
Тогда \eqref{eq:stieltjes} принимает следующий вид:
\begin{equation}\label{eq:stieltjesDiscrete}
    \int_{a}^{b} f(x) dw(x) = \sum_{k=0}^n f(\lambda_k) \Delta w(\lambda_k)
\end{equation}

К виду \eqref{eq:stieltjesDiscrete} мы приведём билинейную форму \eqref{eq:hutch}. \\

Пусть матрица $ A \in \mathds{R}^{n \times n} $ симметричная, $ A = X \Lambda X^T $ -- её разложение по собственным значениям и собственным векторам, $ \Lambda = diag(\lambda_1, \dots, \lambda_n) $, $ \lambda_n \le \dots \le \lambda_1 $.
Тогда в силу того, что
$ f(A) \defeq X \cdot diag(f(\lambda_1), \dots, f(\lambda_n)) \cdot X^T $,
\begin{equation} \label{eq:quadToSum}
    u^T f(A) u = (X^T u)^T \cdot diag(f(\lambda_1), \dots, f(\lambda_n)) \cdot (X^Tu) = \sum_{k=0}^n (X^Tu)_k^2 f(\lambda_k)
\end{equation}

Положив в формуле \eqref{eq:stieltjesDiscrete} $ a \le \lambda_n, b \ge \lambda_1 $ и узлы $ w_k := \sum_{j=k}^n (X^T u)_j^2 $, получим в точности \eqref{eq:quadToSum}.
Окончательно имеем:

\begin{equation} \label{eq:quadToIntegral}
    \boxed{ u^T f(A) u = \int_a^b f(x) d w(x) }
\end{equation}

где

\begin{gather*}
    w(x) = \begin{cases}
        w_{n+1}, x < \lambda_n \\
        w_j, \lambda_j \le x \le \lambda_{j-1} \\
        w_1, \lambda_1 < x
    \end{cases} \\
    \lambda_j : A = X^T \Lambda X, \Lambda = \begin{pmatrix}
        \lambda_1 & 0 & 0 & \dots & 0 \\
         0 & \lambda_2 & 0 & \dots & 0 \\
         & & \ddots \\
         0 & \dots & 0 & \lambda_{n-1} & 0 \\
         0 & 0 & \dots & 0 & \lambda_n
    \end{pmatrix} \\
    w_j := \sum_{j=k}^n (X^T u)^2_j \\
    a \le \lambda_n, \space b \ge \lambda_1 \\
\end{gather*}

\subsection{Квадратуры Гаусса. Связь с тридиагонализацией}

\emph{Квадратурами Гаусса} для интеграла Римана-Стилтьеса называют приближение \eqref{eq:stieltjes} суммой следующего вида:

\begin{equation}\label{eq:gaussQuad}
    I(f) \approx I_G(f) := \sum_{i=1}^k w_i f(t_i)
\end{equation}

где $ \{w_i\}_{i=1}^k, \{t_i\}_{i=1}^k $ выражаются из условия $ I(P_{2k-1}) \equiv I_G(P_{2k-1}) $ $ \forall P_{2k-1} $; $ P_{s} $ обозначает вещественный полином степени $ s $.

Показано \cite{golub2013matcomput}, что для неизвестных коэффициентов в \eqref{eq:gaussQuad} справедливы следующие утверждения:

\begin{enumerate}
    \item Для интервала $ [a;b] $ и весовой функции $ w(x) $, заданных в разделе \ref{section:stieltjes}, всегда найдётся набор полиномов $ \{ p_0(\lambda), p_1(\lambda), ... \}: deg(p_k)=k $, и притом
    \[ \int_a^b p_i(\lambda)p_j(\lambda) dw(\lambda) = \begin{cases}
        0, i \ne j \\
        1, i = j
    \end{cases} \]
Эти полиномы определены с точностью до знака и могут быть выражены через рекуррентное соотношение:
\begin{equation}\label{eq:gaussRecur}
    \gamma_k p_k(\lambda) = (\lambda-\omega_k) p_{k-1}(\lambda) - \gamma_{k-1}p_{k-2}(\lambda)
\end{equation}

где $ \{\omega_k\}, \{\gamma_k\} $ -- некоторые последовательности вещественных чисел; $ p_{-1}(\lambda) \equiv 0, p_0(\lambda) \equiv 1 $.

\item Нули $ \{ \theta_j \}_{j=1}^k $ полиномов $ p_k(\lambda) $ есть собственные числа трёхдиагональной матрицы $ T_k $, определяемой следующим образом:
\begin{equation}\label{eq:Tk}
    T_k := \begin{pmatrix}
        \omega_1 & \gamma_1 & 0 & 0 & 0 & 0 & \dots & 0 \\
        \gamma_1 & \omega_2 & \gamma_2 & 0 & 0 & 0 & \dots & 0 \\
        0 & \gamma_2 & \omega_3 & \gamma_3 & 0 & 0 & \dots & 0 \\
        0 & 0 & \ddots & \ddots & \ddots & 0 & \dots & 0 \\
        \vdots \\
    \end{pmatrix}
\end{equation}

\item Узлы $\{t_k\} $ и веса $ \{w_k\}$ в квадратурной формуле \eqref{eq:gaussQuad} выражаются через спектр матрицы $ T_k $:
\begin{equation}\label{eq:nodesCalculation}
    S^T T_k S = diag(\theta_1, \dots, \theta_k) \Rightarrow t_i = \theta_i, \omega_i = s_{1i}^2, i \in \{ 1;k \}
\end{equation}
Отсюда немедленно следует
\begin{equation}\label{eq:gaussSpector}
    \boxed{ I_G(f) = \sum_{i=1}^k s_{1i}^2 f(\theta_i) }
\end{equation}
\end{enumerate}

Задавшись неким значением $k$ и используя \eqref{eq:hutch}, \eqref{eq:quadToIntegral} и \eqref{eq:gaussSpector}, несложно оценить значение $ tr(f(A)) $.
Необходимо, однако, вычислить неизвестные элементы трёхдиагональной матрицы $ T_k $, а также её собственные числа и векторы.
Это можно эффективно сделать, применяя \emph{алгоритм Ланшоца}.

\subsection{Алгоритм Ланшоца}

Пусть $ A \in \mathds{R}^{n \times n} $ и мы хотим решить задачу о собственных значениях $ A $.

Как показано в \cite{golub2013matcomput}, в случае, когда $ A $ -- симметричная положительно определённая матрица, % TODO что, если матрица не положительно определённая?
первое собственное число $ \lambda_1(A) $ и соответствующий собственный вектор можно получить максимизацией \emph{отношения Рэлея}:

\begin{equation}\label{eq:rayleigh}
    r(x) \defeq \frac{x^T A x}{x^T x}, x \in \mathds{R}^n, x \ne 0 \Rightarrow \max r(x) = \lambda_1(A)
\end{equation}

Задавшись неким начальным вектором, будем по шагам искать в его окрестности максимум $ r(x) $.
Выражение для градиента

\begin{equation}\label{eq:rayleighGrad}
    \nabla r(x) = \left( \frac{\partial}{\partial x_i} r(x) \right) \overset{\eqref{eq:rayleigh}}= \frac{2Ax}{x^Tx} - \frac{2x \cdot x^T Ax}{(x^Tx)^2} = \frac{2(Ax-r(x)x)}{x^Tx}
\end{equation}

Рассмотрим некоторую систему ортогональных векторов
\begin{equation}\label{eq:orthog}
    \{ q_1, \dots, q_n \} \subset \mathds R ^n, q_i \underset{i \ne j}\bot q_j
\end{equation}

Введём обозначения: пусть $ Q_k := (q_1, \dots, q_k), k \le n $; пусть также $ M_k $ -- максимальное собственное число $ A $ в пространстве, натянутом на столбцы $ Q_k $, $ m_k $ -- минимальное.
Иначе,

\begin{gather}
    \label{eq:Mk}
    M_k := \lambda_1(Q_k^T A Q_k) = \max_{ y \ne 0 } \frac{ y^T Q_k^T y}{y^Ty} = \max_{ y \ne 0 } (r(Q_k y)) \le \lambda_1(A) \\
    \label{eq:mk}
    m_k := \lambda_n (Q_k^T A Q_k) = \min_{ y \ne 0 }(r(Q_k y)) \ge \lambda_n(A)
\end{gather}

Заметим:

$ ran(Q_1) \subset ran(Q_2) \subset \dots \subset ran(Q_n) \overset{\eqref{eq:Mk}, \eqref{eq:mk}}\Longrightarrow $
$ \begin{cases}
    M_1 \le M_2 \le \dots \le M_n = \lambda_n(A) \\
    m_1 \ge m_2 \ge \dots \ge m_n = \lambda_1(A)
\end{cases} $

Следовательно, если мы найдём способ шаг за шагом вычислять $ M_k $, сможем поэтапно приближаться к $ \lambda_n(A) $.

Станем действовать по следующей схеме: введя некий вектор $ q_0 $, будем последовательно достраивать $ \{ q_k \} $.
Рассмотрим векторы $ u_k \in span \{q_1, \dots, q_k\}: M_k=r(u_k) $ (т. е. начинаем с $ u_0 \in  span\{ q_0 \} $ и на каждом шаге расширяем пространство поиска).
Если $ \nabla r(u_k)=0 $, то $ (r(u_k), u_k) $ -- собственное значение и собственный вектор $ A $, соответственно, можно выйти из процесса итерирования.
В противном случае выбираем

\begin{equation}\label{eq:qk1}
    q_{k+1} : \nabla r(u_k) \in span \{ q_1, \dots, q_k \}
\end{equation}

Вследствие того, что

\[ \begin{cases}
    \forall x \quad \nabla r(x) \in span\{ Ax, x \} \text{ в силу \eqref{eq:rayleighGrad} } \\
    u_k \in span \{ q_1, \dots, q_k \}
\end{cases} \]
можно выбрать последовательность $ u_k \in span \{ q_1, Aq_1, \dots, A^{k-1} q_1 \} $. Многообразия этого вида называются \emph{подпространствами Крылова} \cite{golub2013matcomput}:

\begin{equation}\label{eq:krylov}
    \mathcal{K}(A, q_1, k) \defeq span \{ q_1, \dots, A^{k-1}q_1 \}
\end{equation}

Поставив условие \eqref{eq:qk1}, мы не указали способ нахождения $ q_{k+1} $.
Т. о., стоит задача построения ортонормированного базиса $ Q_k $ (он же -- ортонормированный базис \eqref{eq:krylov}).

В \cite{golub2013matcomput} показано, что для матрицы $ Q := [ q_1 | \dots | q_n ] $ верно следующее: если
\begin{equation}\label{eq:QDefinition}
    \begin{cases}
        QQ^T = I_n \\
        Q^T AQ = T \text{ (трёхдиагональная симметричная матрица)}
    \end{cases}
\end{equation}

то $ Q[e_1 | Te_1 | T^2 e_1 | \dots | T^{n-1} e_1] = Q Q^T \mathcal K (A, q_1, n) = \mathcal K (A, q_1, n) $ (QR-разложение $ \mathcal K (A, q_1, n) $).

Будем строить столбцы матрицы $ Q $, удовлетворяющей условиям \eqref{eq:QDefinition}.
Введём обозначения для элементов $ T $:

\[ T = \begin{pmatrix}
    \alpha_1 & \beta_1 & 0 & \dots & 0 \\
    \beta_1 & \alpha_2 & \beta_2 & \ddots & \vdots \\
    0 & \beta_2 & \alpha_3 & \beta_3 \\
    \vdots & \ddots & \ddots & \ddots \\
    0 & \dots & 0 & \beta_{n-1} & \alpha_n
\end{pmatrix} = \begin{pmatrix}
t_1 & t_2 & \dots & t_n
\end{pmatrix} \]

$ AQ = QT \Rightarrow $

\begin{equation}\label{eq:preLanczos}
    \begin{cases}
        Aq_1 = \alpha_1 q_1 + \beta_1 q_2 \\
        Aq_2 = \beta_1 q_1 + \alpha_2 q_1 + \beta_2 q_3 \\
        \vdots \\
        \boxed{ Aq_k = \beta_{k-1} q_{k-1} + \alpha_k q_k + \beta_k q_{k+1} \overset{\eqref{eq:orthog}}= \alpha_k q_k } \text{ (полагаем } \beta_0 q_0 \equiv 0 \text{) }
    \end{cases}
\end{equation}

Рекуррентное выражение \eqref{eq:preLanczos} уже позволяет, имея какой-либо вектор $ q_1 \in \mathds R^n: ||q_1||_2 = 1 $, вычислять $ q_k $:

\begin{equation}\label{eq:lanczos}
    \begin{cases}
        \beta_0 q_0 \equiv 0 \\
        \alpha_k = q_k^T Aq_k \\
        r_k := \left( (A-\alpha_k I_n)q_k - \beta_{k-1} q_{k-1} \right) \\
        \beta_k = || r_k ||_2 \\
        q_{k+1} = \frac{r_k}{\beta_k}
    \end{cases}
\end{equation}

(здесь используется то, что векторы $ q_{k-1} $ и $ q_k $ всегда единичные).

Отметим, что таким образом нам на каждом шаге известны элементы матрицы $ \tilde T_k $ -- блока матрицы $ T $, опирающегося на главную диагональ.

В \cite{golub2013matcomput} показано, что при решении задачи о вычислении билинейной формы вида \eqref{eq:quadToIntegral} $ T_k \equiv \tilde T_k $, т. е. в выражении \eqref{eq:Tk} $ \gamma_i \equiv \beta_i $, $ \omega_i \equiv \alpha_i $ (и в выражении \eqref{eq:nodesCalculation} узлы $ t_i $ с ростом $ k $ приближаются к собственным числам $ A $).

Таким образом, окончательная схема решения такова: задаём $ k $ и $ p $, после чего применяем \eqref{eq:hutch}, \eqref{eq:quadToIntegral}, \eqref{eq:gaussSpector} и \eqref{eq:lanczos}, вычисляя в \eqref{eq:gaussSpector} собственные значения трёхдиагональной матрицы каким-либо из стандартных способов, что занимает линейное относительно $ k $ время. % TODO немного об этих стандартных способах
