\documentclass[main.tex]{subfiles}
\begin{document}

\section{Лекция 3. }

\subsubsection{Критерий ранговых знаков Вилкоксона}

Для каждого значения пробы (гена) есть значение экспрессии, вычисляем разность с учётом знака и берём по модулю.

Разности ранжируем по абсолютной величине.
Если два одинаковых значения, считаем ранг средним (например, 4 и 5 по модулю одинаковые $ \Rightarrow $ ранг обоих $ 4.5 $).
Далее берём и считаем сумму рангов по всем отрицательным и по всем положительным значениям отдельно.

Искомая статистика есть меньшее из двух значений. % TODO a bit of text here

Она хорошо аппроксимируется нормальных распределением, поэтому берётся $ Z $-статистика (отклонение нормированного гауссова распределения).

\subsubsection{Алгоритмы кластеризации}

Напомним, есть данные по экспрессии; в первую очередь они нужны, чтобы определить дифференциальную экспрессию (разницу между опытом и контролем).

Следующая идея: можно по этим данным выделить группы генов (применяя кластерный анализ).
Гены, у которых возросла/уменьшилась экспрессия одновременно, имеют, наверное, общий регулятор.
Поэтому выделяем группы совместно регулируемых генов, после чего смотрим, что в этих группах происходит с сайтами посадки ТФ, которые отвечают за регуляцию.

Как-то нужно количественно оценить сходство между экспрессиями.
Это делают с помощью попарной функции сходства.
Естественная мера -- \textbf{расстояние Минковского}

Пусть есть $ p $ экспериментов $ \Rightarrow $ имеем $ p $-мерный вектор.

Можно также считать коэффициент корреляции Пирсона или Спирмана (Пирсона можно только тогда, когда данные распределены по нормальному закону).

Проблема возникает, когда % TODO

Если нет пропусков, то всё ОК; гены, где есть пропуск, нужно отбрасывать.
Тогда расстояние (например, евклидово) корректируется.
Если $ k $ сравнений с пропусками, а всего $ p $, корректируям, умножая на % TODO a bit + formula

\subsubsection{Трансформация данных перед вычисл}

Евклидово расстояние говорит, что вектор % TODO
Если вычислить коэффициент корреляции, окажется иное.
Где истина?
Вводят дополнительное геометрическое преобразование: каждый вектор делится на его евклидову норму.


\subsubsection{Собственно кластеризация}

Нужна не простая, а иерархическая кластеризация.
Как её делают?

Есть $ p $-мерный массив данных (результат $p$ экспериментов).
\begin{enumerate}[noitemsep]
	\item Считаем попарные расстояния, начиная с самого детального разбиения (все элементы).
	\item Выполняем итерации: разбили, посчитали расстояния между кластерами; объединяем два кластера, если расстояние между их центрами меньше заданного порога; повторяем расчёт расстояния между кластерами.
\end{enumerate}

Получается \emph{тепловая карта} (heatmap).

Расстояние считаем, как в методе UPGMA, но там считали расстояния между соседями, а тут между кластерами.
UPGMA считает по среднему арифметическому, можно разными способами.

\begin{enumerate}[noitemsep]
	\item Близлежащий сосед (Single Linkage)
	\item % TODO
	\item Average Linkage (используется чаще всего)
\end{enumerate}

Существует множество методов иерархической кластеризации.
Самый распространённый -- k-means.
Он минимизирует среднеквадратичное отклонение точек кластеров от их центров (<<центры масс>>).
На каждой итерации производится пересчёт центров кластеров.
Завершение -- когда изменения кластеров больше не происходит.

Недостаток метода -- нужно заранее задать число $k$; другой недостаток -- обычно попадаем в локальный минимум. \\

Наиболее часто используется модификация этого метода -- последовательный k-means.

\subsubsection{Последовательный k-means}

У этого метода два параметра: $ \rho $ и $ \sigma $.

Вводим \emph{вес} кластера -- 

% TODO

Повторяем итерации до тех пор, пока расстояние между центрами кластеров не будет больше заданного порога.

\subsubsection{title}

Как проверить, насколько хорошо мы кластеризовали?
Как сравнить разные методы кластеризации?


\begin{enumerate}[noitemsep]
	\item Коэффициент Жаккарда: сравниваем два метода кластеризации.
	Каждый результат разбиения можно представить в виде матрицы $ C_{n \times n} = \{c_{ij}\} $, где будет стоять $ 1 $, если $ i,j $ в одном кластере, иначе $ 0 $.
	
	Сравниваем две матрицы.
	Итоговая метрика -- количество совпадений, делённое на количество совпадений за вычетом числа несовпадений.
	
	\item Силуэтный индекс -- более важный параметр: он оценивает, насколько хорошо прошла кластеризация.
	\begin{enumerate}[noitemsep]
		\item Кластеры должны быть компактными (точки близко друг к другу)
		\item Кластеры должны быть изолированными (не перекрываться). Вторая метрика оценивает степерь изоляции.
	\end{enumerate}
	
	$$ Sl(x_i) = \frac{b_i-a_i}{\max\{a_i,b_i\}} $$

	Силуэтный индекс может принимать значения от -1 до 1.
\end{enumerate}

% TODO выводы

Надо посмотреть, нет ли среди генов множества одинаково аннотированных (не обогащён ли кластер генами с похожими аннотациями, то есть со схожими функциями).
Если есть, то смотрим на их регуляторные районы...

Как аннотировать гены?
По \emph{онтологии}.

\subsubsection{Что такое онтология?}
Простейший пример онтологии -- словарь.
Вообще говоря, онтология -- учение о сущностях и взаимоотношениях.

Биология -- не математика, в ней широко используется жаргон, синонимы, понятия высокого и низкого уровня (например, фермент и киназа фермента).

Пример: B, C, E могут обозначать на жаргоне гены bicoid, caudal, even-skipped.

Gene Ontology (geneontology.org) -- база данных, которая аннотирует белки.

[далее идёт пример поиска в базе Gene Ontology гена бета-субъединицы гемоглобина человека, найденного в GenBank, а также на примере показываетя геномный браузер. Без особенного успеха, можно не смотреть.]

Кроме онтологии GO есть и другие; каждая база данных генов содержит свою онтологию.
Пример -- база данных MGI (мышиных генов).

[далее идёт пример онтологии для гена циклин-зависимой киназы мыши.
Киназы -- ферменты, которые добавляют фосфорный остаток к молекуле; циклины участвуют в делениях клетки.
Также рассматриваемый белок участвует в синтезе цитокинов и ДНК-репарации.
Присутствует в цитоплазме и ядре.

В Gene Ontology для термина <<ATP binding>> перечислены термины более низкого уровня.
Можно посмотреть, какие гены аннотированы этим термином.
Также можно посмотреть для каждого гена, какая у него аннотация.
Но обычно аннотацией GO не пользуются: пользуются полем <<Gene Ongology>> для каждого гена, и есть программы, которые автоматически обрабатывают эту информацию. ]

\subsubsection{Мера избыточной представленности генов в кластере}

Хотим понять, содержит ли кластер гены, одинаковые по функции.
Задача решается по схеме, аналогичной урновой.

Есть кластер. Мы знаем, сколько из них принадлежат тому или иному функциональному классу.
Надо понять, является ли принадлежность группы генов определённому классу случайным событием или нет.

Если случайно, а не обогащённость генами некоторого функционального класса, то значение описывается гипергеометрическим распределением.

KEGG (kegg.jp) - Kyoto Encyclopedia of Genes And Genomes.
Это база данных метаболических путей.

[далее пример KEGG: в метаболизме клетки -- трикарбоновый цикл (цикл Кребса), нуклеотидный метаболизм, синтез жирных кислот... сплайсосома... мап-киназа...
Замечание: биологические системы очень сложны, и за редким исключением модели, описывающие их, неверны.

Эндоцитоз (впячивание мембраны)...
Синтез клеток крови... ]


Нас интересует \emph{сверхпредставленность}: обогащён ли кластер генами из некоторого пути $ i $.

Используем критерий Вилкоксона (см. начало лекции).
Берём разности по абсолютной величине, ранжируем, считаем суммы по положительным и отрицательным, сравниваем значение Z-статистики.


\end{document}
