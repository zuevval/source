% compile with XeLaTeX or LuaLaTeX

\documentclass[a4paper,12pt]{article} %14pt - extarticle
\usepackage[utf8]{inputenc} % russian, do not change
\usepackage[T2A, T1]{fontenc} % russian, do not change
\usepackage[english, russian]{babel} % russian, do not change

% fonts
\usepackage{fontspec} % different fonts
\setmainfont{Times New Roman}
\usepackage{setspace,amsmath}
\usepackage{amssymb} %common math symbols
\usepackage{dsfont}

% utilities
\usepackage{hyperref}
\hypersetup{pdfstartview=FitH,  linkcolor=blue, urlcolor=blue, colorlinks=true}

\begin{document}

\section{11. Эвристические методы выравнивания; 12. Алгоритмы попарного выравнивания, основанные на эвристическом подходе. 13. Поиск по банку, хэширование}
\href{https://vk.com/doc155237002_518129852?hash=c14fcc0da730fc8e60}{Книга -- Durbin et al:} Pairwise alignment / Heuristic alignment algorithms: \textsection 2.5, page 32 \\
\href{https://vk.com/doc155237002_518129974?hash=8b75ee93da5460098c}{Перевод -- Дурбин Р. и другие:} Выравнивание двух последовательностей / Эвристические алгоритмы выравниваний: \textsection 2.5, стр. 57 \\
YouTube: \href{https://youtu.be/gGoYQBBEX8M?t=689}{Лекция 2; 0:11:29 -- 0:16:48} \\
Презентации в ВК: \href{https://vk.com/doc155237002_519204981?hash=9c4f1a66b95c4fd7fa}{lecture3.pdf}
\hrule \vspace{10pt}

Алгоритмы динамического программирования гарантируют нахождение оптимального выравнивания, но работают долго. Если задача -- выровнять последовательность относительно последовательностей из базы (например, GenBank), мы умрём искать!

\begin{itemize}
	\item Динамическое программирование - $O(mn)$
	\item Эвристики: жертвуем чувствительностью ради быстроты (можем не найти выравнивание с наибольшей стоимостью)
\end{itemize}
Основная идея: в сходных последовательностях обязательно найдутся короткие почти идентичные участки. Ищем их, а затем расширяем выравнивание в обе стороны (\textit{seed-and-extend approach}).

Базы данных хэшированы, т. е. составлены таблицы: ключ -- \textit{l-tuple} (l-грамм), значение -- список последовательностей с указанием мест, где этот l-tuple встречается. Например, 3-tuple AGT встречается в TAAGTC. 

Поиск последовательности (query) в базе начинается с нахождения всевозможных l-tuple в хэш-таблице. Пара совпадающих l-tuples -- \textit{seed}, <<затравка>> -- начало, от которого будем пытаться расширить выравнивание. 

\newpage
\section{16. Алгоритмы выравнивания, линейные по памяти, для случая с линейным штрафом за пробел}
Книга Дурбина. \textsection 2.6 Выравнивание с линейной памятью (стр. 60-62) -- здесь алгоритм Миллера-Маерса не приведён, вместо него чуть более простой. Думаю, не стоит тратить своё время на чтение этого места в Дурбине.\\
Задачник Бородовского. \textsection 2.1 Попарное выравнивание. Оригинальные задачи / Задача 2.11 и 2.12 (стр. 67-69) -- тоже не совсем Миллера-Маерса!!\\
YouTube: \href{https://youtu.be/gGoYQBBEX8M?t=6}{Лекция 2; 0:00:06 -- 0:02:02} (увы, там только \ref{section:economy_another}, Миллер-Маерс был в первой лекции). \textbf{Так что основная надежда на слайды презентации, благо там кратко и по существу.} \\
Презентации в ВК: \href{https://vk.com/doc155237002_519204981?hash=9c4f1a66b95c4fd7fa}{lecture3.pdf}

\hrule

\subsection{Алгоритм Миллера-Маерса}
Алгоритм вычисляет оптимальное выравнивание за $O(n+m)$ памяти и $O(n*m)$ времени, причём работает в среднем лишь в два раза дольше стандартного алгоритма (см. задачу 2.12 из Бородовского -- хотя там доказывается для чуть упрощённого алгоритма, но смысл тот же).

Идея: вынес в отдельную презентацию. \href{https://csspbstu-my.sharepoint.com/:p:/g/personal/zuev_va_edu_spbstu_ru/EauKoirdykhFlvBuplp5FEgBJBq66QcdmxADVppJ6LDy_g?e=hdDtps}{PPTX (OneDrive)} |  \href{https://csspbstu-my.sharepoint.com/:b:/g/personal/zuev_va_edu_spbstu_ru/EQQON2KiCRlIieAAtAn4FrQBtga-H5GNPHYAN8vxSSwW9A?e=EplqUx}{PDF (OneDrive)}. Можно бы сделать анимацию, но и так сойдёт, надеюсь.

\subsection{Ещё один способ сэкономить время и память}\label{section:economy_another}
Пусть мы хотим найти оптимальное выравнивание из левого верхнего угла в правый нижний. Пути, проходящие в матрице динамического программирования близко к правому нижнему или левому верхнему углу, будут содержать много пробелов. Поэтому разумно ограничить выравнивания полосой.

Алгоритм: фиксируем <<разумную>> ширину полосы и рассматриваем только те значения рядов, которые лежат внутри неё.


\section{17. Значимость оценки стоимости}
Книга Дурбина. \textsection 2.7 Значимость весов \\
YouTube: \href{https://youtu.be/gGoYQBBEX8M?t=2237}{Лекция 2, 37:18}
\hrule \vspace{10pt}

Чтобы понять, велико ли сходство между двумя выровненными последовательностями, сравниваем сходство score их выравнивания со score выравнивания двух \textit{случайных последовательностей}. Случайные последовательности получаем из исходных случайной перестановкой нуклеотидов. Используем статистический подход: гипотеза $H_0$ -- последовательности никак не свазаны, выравнивание случайно; если вероятность $H_0$ мала, отвергаем её и считаем, что сходство двух последовательностей \textbf{статистически значимо}. Для этого статистического теста надо знать распределение score. Это \textit{распределение максимальной оценки}.

\section{18. Распределение экстремальных значений}
Книга Дурбина. \textsection 2.7 Значимость весов / Классический подход: распределение экстремальных значений (стр. 66-68) \\
YouTube: \href{https://youtu.be/gGoYQBBEX8M?t=2478}{Лекция 2, 41:18}
\hrule \vspace{10pt}

Можно вывести распределение экстремальных значений (EVD, Extreme Value Distribution) из теории.
\begin{itemize}
	\item Вес (score) выравнивания конкретной последовательности со случайной -- сумма многих случайных величин, т. о. в пределе описывается нормальным распределением
	\item Возьмём $N$ случайных (сгенерированных) последовательностей. Устремим $N$ к $\infty$. Тогда в пределе максимум $M_N$ по всем score из $N$ выравниваний будет таков:
	$$P(M_N \le x) \approx exp(-KN e^{\lambda(x-\mu)})$$
	где $K, \lambda = const$. Т. о. можем определить, какова вероятность того, что, перебрав $N$ случайных последовательностей, мы среди них найдём ту, которая даст выравнивание с весом не меньше $M_N$. Если эта вероятность мала, то выравнивание, скорее всего, не случайно.
	\item Karlin \& Altschul (1990) показали, что число независимых локальных выравниваний с весом, большим данного, описывается распределением Пуассона.
\end{itemize}

\newpage
\section{19. Z-score}
YouTube: \href{https://youtu.be/gGoYQBBEX8M?t=2901}{Лекция 2, 48:21}
\hrule \vspace{10pt}
В базе при поиске с помощью BLAST используется не вес, а нечто более хитрое -- \textit{Z-score}.

Пусть $S$ -- score выравнивания, $\mu$, $\sigma$ -- среднее и стандартное отклонение score для популяции.Тогда $Z = \frac{S - \mu}{\sigma}$ -- мера отличия score от среднего в популяции. $Z=0 \Rightarrow$ стоимость не лучше средней. Считается, что значимые выравнивания -- те, у которых $Z > 5$ (различие больше 5 стандартных отклонений).

\section{20. Е-values}
YouTube: \href{https://youtu.be/gGoYQBBEX8M?t=3053}{Лекция 2, 50:53}
\hrule \vspace{10pt}
На основании Z-score можно вычислить E-value (expect-value) -- ожидаемое число последовательностей в базе, которые могут быть выровнены с данной с большим score. Чем оно меньше, тем лучше. При увеличении score E-value экспоненциально убывает к нулю.
$E = P \cdot [number of seq-s in database]$.

Если $E \le 0.02$ -- вероятно, последовательности гомологичны. $E > 1 \Rightarrow$ сходство случайно.

\textbf{Связь $E$ и $score$ выравниваний:} BLAST ищет в базе данных сегменты с нормализованным весом $>S$. Их число оценивается формулой \textit{(видимо, следующей из закона Пуассона)}: $E = N / 2^S$, где $N=nm$, $m$ -- длина последовательности, $n$ -- число последовательностей в базе. Отсюда следствие: чтобы находить выравнивания со значением $E$ не меньше заданного, надо положить $S=log_2(N/E)$.

\newpage
\section{21. Поправка на длину последовательности; 22. Зависимость веса выравнивания от длины последоветельности}
Книга Дурбина. \textsection 2.7 Значимость весов / Поправка на длину последовательности (стр. 68-69) \\
YouTube: \href{https://youtu.be/gGoYQBBEX8M?t=4155}{Лекция 2, 1:09:15}
\hrule \vspace{10pt}
Две мысли:
\begin{enumerate}
	\item Вес выравнивания, очевидно, зависит от длины последовательности, т. к. это сумма весов по отдельным позициям.
	\item Когда мы ищем последовательность в базе, вероятность локального выравнивания на более длинную будет больше (там больше мест, куда можно выровняться). Это нехорошо, всё должно быть равновероятно.
\end{enumerate}
Из численных экспериментов оказалось, что зависимость вероятности выравнивания от длины либо логарифмическая, либо линейная в зависимости от настройки параметров BLAST. Если штрафы за несовпадение и \textit{гэпы} (gaps, они же indels=insertions/deletions) велики, зависимость линейная.

Нас интересуют, как правило, безделеционные выравнивания. Поэтому из максимальной оценки сходства $M_N$ вычитаем $log(m_i)$, где $m_i$ -- длина последовательности из базы, на которую выравниваем. Или, как вариант, аппроксимируем распределение оценки сходства линейной функцией от логарифма длины последовательности \textit{(?? не очень понятно, в Дурбине написано на стр. 69, но я всё равно не вполне понимаю; задать вопрос, что ли?)}
	
\end{document}
