% compile with XeLaTeX or LuaLaTeX

\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc} % russian, do not change
\usepackage[T2A, T1]{fontenc} % russian, do not change
\usepackage[english, russian]{babel} % russian, do not change

% fonts
\usepackage{fontspec} % different fonts
\setmainfont{Times New Roman}
\usepackage{setspace,amsmath}
\usepackage{amssymb} %common math symbols
\usepackage{dsfont}

% utilities
\usepackage{amsthm} % theorems with proofs
\usepackage{systeme} % systems of equations
\usepackage{mathtools} % xRightarrow, xrightleftharpoons, etc
\usepackage{array} % utils for tables
\usepackage{makecell} % multirow for tables
\usepackage{subfiles}
\usepackage{hyperref}
\hypersetup{pdfstartview=FitH,  linkcolor=blue, urlcolor=blue, colorlinks=true}
\usepackage{framed} % advanced frames, boxes
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption} % captions for subfigures
\usepackage{color}
\usepackage{listings} % code chunks
\definecolor{dkgreen}{rgb}{0,0.6,0}
\lstset{language=Python,
    basicstyle=\small\ttfamily,
    stringstyle=\color{dkgreen},
    keywordstyle=\color{blue},
    commentstyle=\color{dkgreen},
    tabsize=2,
    breaklines=true,
    columns=fullflexible
}

% styling
\usepackage{float} % force pictures position
\floatstyle{plaintop} % force caption on top
\usepackage{enumitem} % itemize and enumerate with [noitemsep]
\setlength{\parindent}{0pt} % no indents!

% misc
\graphicspath{{./img/}}
\newcommand{\myPictWidth}{.95\textwidth}
\newcommand{\phm}{\phantom{-}}
\newtheorem{problem}{Задача}

\begin{document}

\title{CatBoost -- градиентный бустинг от Яндекса. Конспект лекции Анны Вероники Дорогуш}

\author{Валерий Зуев}

\maketitle

\section{Введение}

CatBoost -- библиотека с открытым исходным кодом, выложена в GitHub; 2.5k скачиваний с PyPi в месяц, библиотека развивается изнутри и даже кто-то коммитил извне.

\subsection{Дерево решений}
В первой вершине есть вопрос (требуется ответ в форме да/нет: как правило, числовой фактор и сравнение на $\glq$). Если ответ <<да>>, идём в одну сторону, <<нет>> -- в другую.
В следующих вершинах тоже могут быть вопросы, отвечая на них

Градиентный бустинг строит ансамбли деревьев.
Сперва есть одно дерево, затем добавляем ещё одно так, чтобы уменьшилась ошибка на обучающей выборке...
Так строим сотни, тысячи или даже десятки тысяч деревьев, и в итоге уже получается что-то, что хорошо ведёт себя на обучающих данных.

\subsection{Режимы}

\subsubsection{Какие задачи можно решать градиентным бустингом в CatBoost?}

\begin{enumerate}[noitemsep]
    \item Самое простое -- \textbf{регрессия}: есть данные, есть метки и хотим приблизить метки.
    Функция потерь -- MSE (mean square error).
    \item \textbf{Классификация} -- немного посложнее.
    Рассмотрим пример бинарной классификации.
    Хотим, чтобы ответ модели можно было отождествить с вероятностью попадания в класс, то есть ждём число от 0 до 1.

    Как заставить большой ансамбль деревьев давать ответ в отрезке от 0 до 1?
    Максимизируем вероятность того, что все объекты в обучающей выборке распознаны правильно.
    В качестве вероятности используем сигмоиду от значения классификационной формулы $y$:
    $$ p = \sigma(y) = \frac{1}{1+e^{-x}} $$
    Это гладкая s-образная кривая
    

    \begin{leftbar}
        Если при использовании CatBoost для классификации использовать функцию \texttt{predict}, получится не вероятность, и тогда, к примеру, можно складывать выходы от разных моделей.
        Если \texttt{predict\_proba} -- будет взята сигма-функция, и на выходе вероятность.
    \end{leftbar}
    С мультиклассификацией почти то же, только в листьях деревьев не 0/1, а несколько чисел (меток классов), они учатся одновременно.
    Соответственно, надо на выходе получить не одну вероятность попадания в позитивный класс, а вероятности всех классов; поэтому вместо сигмоиды берём softmax-функцию (многомерное обобщение сигмоиды):
    $$ Softmax(\vec y) = \frac{1}{\sum_i} e^{y_i} \begin{pmatrix} e^{y_1} \\ e^{y_2} \\ \vdots \end{pmatrix} $$

    \item \textbf{Ранжирование:} есть ранжирование и попарная классификация.
    \textit{Попарная классификация:} есть датасет (набор объектов + для каждого набор признаков). Их нужно поставить в одну очередь. Для каждой пары объектов мы знаем, какой элемент пары лучше бы поставить в очереди прежде другого.
    Т. о. задача алгоритма -- подобрать такую формулу, чтобы ранжировать пары как можно лучше.
    Максимизируем вероятность того, что как можно больше пар ранжированы в правильном порядке: берём сигмоиду от разностей значений формул.

    \textit{Ранжирование:} есть датасет, разбитый по группам.
    Нужно как можно лучше ранжировать каждую группу.

    Как правило, в задаче ранжирования в каждой группе составляют свой набор пар и стараются составить очередь так, чтобы как можно больше пар шли в правильном порядке.

    Замечание: при ранжировании нам совершенно неважно абсолютное значение формулы, т. о. мы не можем, к примеру, сравнивать значение с некоторым допустимым порогом и на основе этого делать выводы.
    Важно только то, как объекты друг с другом сравнивать.
\end{enumerate}

\subsubsection{Оптимизируемая функция и метрики}

Оптимизируемая функция всегда одна, а метрик может быть много, и за ними можно следить во время обучения.
Например, при бинарной классификации можно максимизировать logloss, но при этом ещё смотреть на значение AUC и <<обрезать>> формулу по лучшему значению AUC.
\begin{leftbar}
	LogLoss для бинарной классификации складывается из слагаемых вида:
	$$ L_{log}(y_i, p_i) = -(y_i \log(p_i) + (1-y_i) \log(1-p_i)) $$
	Здесь $ y_i \in \{0, 1\} $ -- метка класса, $p_i \in [0;1]$ -- предсказанная вероятность.
	Можно заметить, что одно из двух слагаемых в этой формуле всегда ноль, а второе таково, что градиент $\frac{\partial L_{log}}{\partial p_i}$ направлен в сторону уменьшения отклонения $p_i$ от $y_i$.  \\
	
	AUC (area under curve) -- площадь под графиком в осях False Positive Rate / True Positive Rate при варьировании порога вероятности, по которому мы разделяем позитивный класс (1) и негативный (0).
\end{leftbar}
По одним метрикам можно сделать overfitting detector, по другим -- обрезать формулу; в целом можно просто взять много метрик и построить их графики в зависимости от итерации.

\subsection{CatBoost Viewer}

Очень полезно пользоваться визуализацией.
\begin{enumerate}[noitemsep]
    \item В Jupyter Notebook (Python) можно в функцию \texttt{fit} передать флаг \texttt{plot=true}, и тогда построится график.
    При этом можно сравнивать несколько моделей.
    \item В R нет встроенной визуализации, но тот же инструмент (CatBoost Viewer) всегда можно использовать в браузере.
    \item В TensorBoard тоже можно смотреть на те же графики.
\end{enumerate}

\section{Обучение модели. Общие сведения}

\subsection{Схема обучения}

Сначала строим дерево, затем считаем значения в листьях (обычно считают значения в листьях при построении, но в CatBoost иначе).

Дерево строится \textit{жадно}: сначала выбираем первую вершину дерева; затем делаем вид, что дерево состоит только из этой вершины и перебираем все возможные деревья из одной вершины.
Каждому одновершинному дереву присваиваем score и выбираем лучшее.
Затем добавляем вторую вершину и так далее.  \\

Краткий обзор алгоритмов добавления вершин в разных библиотеках:
\begin{itemize}[noitemsep]
    \item LightGBM (Light Gradient Boosting Machine) делает так: строит деревья в глубину (сначала одна, потом вторая вершина...).
    Могут получиться чересчур глубокие, <<однобокие>> деревья.
    \item XGBoost строит деревья по слоям: сперва первый ярус, затем следующий (впрочем, не обязательно заполняются все вершины, дерево может быть и несимметричным).
    После построения делается pruning (обрезка деревьев).
    \item CatBoost: деревья тоже строятся по слоям, но задано ограничение: во всех узлах на одном уровне производится сравнение по одному и тому же признаку.
\end{itemize}

\subsection{Score разветвления}

Как в CatBoost выбирается лучшее ветвление?

Есть несколько способов оценки разделения.

\begin{enumerate}[noitemsep]
    \item Строим дерево жадным способом; считаем значение в листьях и оцениваем, насколько оно хорошее.
    Например, смотрим, насколько меняется функция ошибки по сравнению с предыдущим вариантом дерева.
    \item Будем строить дерево так, чтобы оно как можно лучше вектора градиента.

    Отступление.
    Как работает градиентный бустинг?
    Есть $ n $ объектов (например, документов), есть функция ошибки от $ n $ переменных, где каждая переменная -- значение ответа ансамбля на соответствующем входе.
    Градиент этой функции есть  $ n $-мерный вектор.

    Листьев в дереве наверняка меньше, чем объектов в обучающей выборке (например, при глубине дерева $ 6 $ будет не более $ 64 $ листа).
    Т. о. мы не можем спускаться прямо по градиенту.
    Зато можем смотреть, насколько вектор значений в листьях похож на вектор градиента (и на основе этого строить score):

    $$ score(split) = \frac{\sum_{doc}leafValue(doc) \cdot gradient(doc) \cdot w(doc)}{\sqrt{\sum_{doc} w(doc) \cdot leafValue(doc)^2}} $$
    $$ leafValue(doc) = \frac{sumWeightedDer}{sumWeights} $$

    где $ w(doc) $ -- вес элемента в обучающей выборке.

    Перебираем все возможные разветвления и смотрим, какое даст наибольший score.

\end{enumerate}

\subsection{Bootstrap}

Можно обучаться не на всей выборке одинаково, а выкинуть часть объектов или назначить вес $w$.

Сейчас в CatBoost реализованы два метода для бутстрапа:

\begin{enumerate}[noitemsep]
    \item Бернулли: каждый элемент выборки берём с вероятностью $ sample\_rate $ (это параметр алгоритма).
    $$ w(doc) = 0 or 1 (p(1) = sample\_rate) $$
    \item Байесовский (мы его так называем):
    на каждой итерации добавка к весу элементов сэмплируется из экспоненциального распределения
    $$ w(doc) *= (-log(rand(0,1)))^{bagging\_temperature} $$

    Этот способ хорош тем, что веса могут меняться во всём диапазоне от $0$ до $+ \infty$, но средний будет равен единице.

    Параметр $sample\_rate$ влияет на интенсивность сэмплирования (и на качество).
    Такой способ
\end{enumerate}

Замечание: бутстрап используется только на этапе выбора структуры дерева.
Когда считаем значения в листьях, используем всю выборку целиком.

В других алгоритмах так не делается.

\subsection{Рандомизация score}

Ещё одна вещь, которая делается только в CatBoost:
при выборе лучшего разветвления к score прибавляются случайные величины, зависящие от номера итерации и длины вектора градиента.

$$ score(f) += random\_strength \cdot \mathcal{N}(0, RndMult \cdot Sko), \thickspace Sko \text{ --  длина вектора градиента} $$

Смысл -- ближе к концу обучения хотим меньше случайных факторов, вначале можно побольше.

\section{Работа с факторами. Бинаризация}
Ещё одна важная вещь -- бинаризация факторов.
\subsection{Бинаризация численных признаков}

Представим, что есть числовой фактор, который может принимать разные значения.
Нужно выбрать какое-то разбиение на два множества (идём направо в узле дерева или идём налево).

В XGBoost есть два способа бинаризации.
Одна просто перебирает возможные пороги (это долго), есть версия с гистограммами.

На каждой итерации в XGBoost выбирается новая сетка порогов, что трудозатратно и бесполезно.
В CatBoost сетка выбирается заранее; эксперименты показали, что это не ухудшает качество. \\

Способы построения сетки:

\begin{enumerate}[noitemsep]
    \item Берём значения признаков в обучающем наборе и равномерно строим сколько-то границ от минимального до максимального значения
    \item Медианная сетка: между двумя соседними границами одинаковое количество точек (например, проходим 5 точек, ставим границу сетки; проходим ещё 5 и ставим вторую и так далее).
    Проблема: если в одну точку попадает множество элементов данных, получим меньше границ, чем запросили.
    \item UniformAndQuantiles: половину границ строим равномерным образом, половину -- из медианной сетки.
    \item MaxSumLog / GreedyLogSum

    Вспомним формулу:
    $$ \sqrt[n]{\prod w_i} \le \frac{\sum w_i}{n} \le \sqrt{\frac{\sum w_i^2}{n}} $$
    где $w_i$ -- то, сколько точек попало в интервал разбиения сеткой.

    Хотим максимизировать равномерность разбиения, иначе, достичь в неравенстве равенства. Для этого можем максимизировать левую часть.
    Это то же, что максимизировать $ \sum \log(w_i) $.

    MaxSumLog строит точное оптимальное приближение; GreedyLogSum -- жадное приближение, работает не всегда оптимально, но быстро (поэтому стоит в CatBoost по умолчанию).
\end{enumerate}

\subsection{Сравнение бинаризаций}

Ещё можно при построении сетки попробовать минимизировать не сумму логарифмов, а сумму квадратов, но возникает проблема -- большие корзины штрафуются сильно, к ним ничего не будет присоединяться.
Например, если есть четыре точки, в них $10, 10, 1000, 1$ элементов выборки соответственно, то будет обязательно поставлен порог между $1000$ и $1$, т. о. в одной из корзин будет единственный элемент, что плохо.

\subsection{Бинаризация счётчиков}

\begin{enumerate}[noitemsep]
    \item на CPU -- равномерная (это быстрее считать)
    \item на GPU -- любая
\end{enumerate}

\subsection{Вычисление значений в листьях}

Почему значения в листьях вычисляются не во время построения дерева, а отдельно?
Когда выбираем split, надо сделать очень много операций (для каждого разбиения вычислить дерево и его качество).
Поэтому стараемся делать это наиболее эффективным способом (градиентный спуск).

Когда считаем значения в листьях, уже больше времени.
Поэтому можем делать шаги по Ньютону (дороже по времени, но лучше приближение).

Внутри одного дерева можно делать несколько шагов по градиенту или методом Ньютона! (посчитали значение градиента, пересчитали значение в листьях, после чего пересчитываем значение формулы -- и так несколько раз, можно шагать по градиенту, можно методом Ньютона). Идея была ещё в MatrixNet.

\subsection{Работа с категориальными факторами}

С числовыми факторами примерно понятно, как делать бинаризацию (сравниваем с пороговым значением).
Если признак категориальный, возможны несколько стратегий.
\begin{enumerate}[noitemsep]
    \item Перенумеровать факторы (дать им номера от $0$ до $k$) и использовать как числовой фактор.
    Это плохо работает.
    \item One-hot encoding: если был фактор, например, <<профессия>> со значениями <<врач>>, <<инженер>> и <<программист>>, то теперь будет три фактора (три ветвления): <<является ли человек врачом>>, <<является ли человек программистом>>, <<является ли инженером>>.
    Хорошо работает, если значений признака мало.
    \item Хэширование в несколько корзин: уменьшение числа значений признаков путём объединения в группы (затем, к примеру, one-hot encoding).

    Тоже никогда не работает!
    Гораздо лучше сделать топ-сколько-то значений признаков и с ними работать.
\end{enumerate}

Это самые простые способы. Есть и более продвинутые, о них дальше идёт речь.

\subsection{Статистики по категориальным признакам}
Что еще можно сделать?
\begin{enumerate}[noitemsep]
\item Был категориальный признак, решаем заменить его новым числовым признаком. В качестве числового признака будем использовать среднее значение метки по датасету – средний таргет по пулу. Это не работает, поскольку приводит к переобучению. Переобучение легко демонстрируется примером, когда имеется всего один объект с данным значением категориальной фичи. Тогда новое значение числового признака будет совпадать с меткой. 
\item Можно считать средний таргет с использованием техники leave one out – считать среднее по всем объектам кроме данного. Тоже не работает! Например, имеется один категориальный признак «животное». Имеется значение «кот», с этим значением в датасете $4$ успеха и $7$ неудач. Первым узлом разделения будет условие «кот-не кот», вторым узлом в ветке «кот» будет счетчик. Если используется принцип leave one out, то имеется всего два значения счетчика: $0.3 = 3/10$ (3 успеха при убранном одном объекте) или $0.4 = 4/10$. В таком случае в одной ветке находятся все неудачи, а в другой – все успехи. Поэтому также произойдет переобучение.
\item Leave bucket out – подход, при котором датасет разбивается на $2$ или более частей, в одной из которых считается среднее, а на второй оно применяется. То же самое, что и leave one out, только на большем числе объектов. Приводит к переобучению.
\end{enumerate}

\textit{Отступление:} счетчик – статистика по категориальному признаку. Например, имеется значение «кот» и «не кот». Значение статистики в п. №2 считается как процент успехов/неудач. Значение «кот» будет заменено на числовое значение доли успехов, значение «не кот» будет заменено на значение доли неудач. \\
\\

\textbf{Какие же способы все-таки работают?} \\

Например, средний таргет по отложенной выборке: выборка делится на две части. На одной считаются средние таргеты, то есть новые числовые категориальные признаки, а на другой происходит переобучение. Подход работает, но при этом в два раза уменьшается как обучающая выборка, так и те данные, на которых считаются счетчики. \\
 
\textbf{Как делается в CatBoost?}  \\

Чтобы не было переобучения, будет тоже считаться среднее, но для каждого объекта по-новому: 
\begin{enumerate}[noitemsep]
\item На датасете делается случайная перестановка (поскольку объекты могут быть заранее упорядочены по успехам/неудачам). 
\item Рассматривается значение категориальной фичи для конкретного объекта, например, «животное»: «кот». Затем рассматриваются все объекты, которые выше данного в перестановке, с тем же значением «кот». По этим объектам и высчитывается средний таргет – по «прошлому» каждого объекта. 
\end{enumerate}

Такую процедуру можно проделывать во время предобработки данных: для каждого объекта вместо категориального признака оставить значение счетчика. \\

\textbf{Как можно улучшить приведенный алгоритм?} \\

\textbf{Нельзя:} использовать несколько перестановок! Это значит, что для каждого объекта будет несколько счетчиков на каждой из случайных перестановок, что приведет к переобучению.

\textbf{Можно:}
 \begin{enumerate}[noitemsep]
\item Обучать параллельно несколько ($n$) моделей. Каждая модель будет обучаться на своей перестановке. Все модели имеют одинаковую фиксированную структуру дерева. 
Допустим, начинается новая итерация градиентного бустинга, строится новое дерево. Рандомно выбирается одна из $n$ моделей, каждой из которых соответствуют некоторые перестановки. Для данной модели выбирается лучшее дерево и объявляется, что это дерево на самом деле лучшее для всех $n$ моделей, и для всех $n$ моделей строятся значения в листьях. 
\item Использовать комбинации категориальных признаков. Допустим, имеется две категориальных фичи, которые имеют по $2$ значения. Тогда, если объединять их в одну на этапе предобработки данных, появится новая фича, которая имеет $2∙2=4$ новых значения. Количество значений будет расти экспоненциально. Все возможные комбинации с учетом старых признаков будет перебрать тяжело. 
\end{enumerate}
\textbf{Что делается в CatBoost:} на каждой итерации градиентного бустинга при выборе дерева комбинации выбирают жадно. Если в текущем дереве была выбрана какая-то категориальная фича, на том шаге, когда перебираются кандидаты для следующего уровня, будут перебираться все комбинации с этой категориальной фичой. Это приводит к большому росту качества – перебираются все комбинации с наилучшими фичами. 

\section{Типы статистик}

Статистики делятся на два типа – те, которые используют таргет (как уже упоминалось выше, когда считается среднее, используется таргет), и те, которые не используют таргет. \\

Например, из тех статистик, которые не используют таргет: частота встречаемости документа. Ее также можно считать во время обучения и по ней строить некоторые комбинации (использовать частоту встречаемости некоторой комбинации). Плюс использования такой статистики в том, что можно сразу смотреть в тестовые данные – частоты будут считаться не только по обучающим данным, но и по тестовым. \\

Счетчики можно считать по-разному для разных режимов.
\begin{enumerate}[noitemsep]
\item Для бинарной классификации считается средний таргет или доля успехов (с точностью до $prior$):
$$ctr=\frac{\#Positive+Prior}{\#All+1}$$
Необходимо грамотно выбирать prior, поскольку по такой формуле для первых объектов получаются значения, близкие к нулю. У CatBoost во время обучения перебирается несколько $prior$, что добавляет качества при обучении. 
\item Для регрессии и мультиклассификации имеется гораздо больше вариантов счетчиков. 
$$ctr=\frac{\#CountInClass+Prior}{\#All+1}$$
\end{enumerate}

\textit{Для регрессии} можно сделать бинаризацию по меткам, получить на метках классификации некоторую сетку, считать успехом для каждой границы то, что справа. Для регрессии лучше работает медианная сетка (лучше, чем равномерная). 
Можно также считать квантили, средний таргет. \\

\textit{Для мультиклассификации} успехом считается попадание в данный класс. Допустим, имеется $k$ классов. Тогда для каждой категориальной фичи будет $k$ разных счетчиков, для каждого из которых успех свой – попадание в данный класс. 

\subsection{Вычисление статистик при применении}

\textbf{Что происходит со счетчиками во время применения?} \\

\textbf{CTR:} Во время применения делается вид, что новый объект дописывается в конец обучающей выборки. Если считается средний таргет, то он просто берется средним по всему обучающему пулу. \\
\textbf{Counter:} считаются по всему тесту или просто дописываются к обучающему датасету.


\section{One-hot encoding}

\textbf{Что важно понимать:} в качестве предобработки не нужно делать one-hot encoding! 
Каждый раз, когда выбирается сплит, присутствует элемент рандома: сначала выбор стоит между сплитами конкретного признака, после этого выбор идет именно между фичами. Если делать one-hot encoding в качестве предобработки, все фичи будут считаться разными, и рандом будет играть в их пользу, что может сказаться на качестве. Также это может замедлить обучение. \\

Для того, чтобы грамотно использовать one-hot encoding внутри алгоритма, нужно использовать флаг $one\textunderscore hot \textunderscore max \textunderscore size$. По умолчанию в CatBoost категориальные фичи подвергаются one-hot encoding с двумя значениями. Обычно, именно двух значений достаточно. Если больше – лучше считать счетчики. 

\section {Переобучение на классическом бустинге. \\ Ordered boosting}

\textbf{Что делает классический бустинг:} строится дерево, значения в листьях которого являются оценками градиента, которые попадают в этот лист. Оценка градиента производится на тех же объектах, на которых модель училась. Это приводит к смещению, если оценить функцию ошибки в листе на новых объектах. На старых объектах ошибка будет меньше. \\

\textbf{Избежать смещения можно с помощью ordered boosting.} \\

Для каждого документа (объекта) оценку градиента будем делать по-своему. Оценивание будет происходить во время построения структуры дерева. Для каждого дерева будет строиться оценка по градиенту не по всем объектам обучающей выборки, а только по тем объектам, которые были раньше данного в перестановках, которые использовались для подсчета счетчиков. \\

\textbf{Квадратичная схема:} \\

Далее поступим следующим образом: будем обучать $n$ моделей, где $n$ – количество объектов (документов) в обучающей выборке. Для каждого объекта будет обучаться отдельная модель с использованием «прошлого» конкретного объекта. \\

\textit{Какова сложность такого алгоритма?} \\

Учить модель на выборке означает, что необходимо хранить и пересчитывать значения формулы на каждом объекте. Для каждой модели будет столько значений формулы, на скольких объектах она учится. На каждой итерации эти значения будут обновляться. Для второго объекта будет одно значение формулы, для третьего – два и т.д. В итоге необходимо хранить и перевычислять на каждом шаге квадратичное количество значений формулы. Если объем датасета большой, то одна итерация градиентного бустинга будет работать очень долго. Поэтому это непрактично! \\

\textbf{Как можно делать (применить линейную схему): } \\

Вместо того, чтобы учить $n$ моделей параллельно, будем учить одну модель, которая выглядит следующим образом:
\begin{itemize}[noitemsep]
\item в модели хранится $n$ значений формулы, где $i$-ое значение формулы (будем называть его $approx$) посчитано только по его прошлому. Всего будет храниться $n$ $approx$-ов.
-\item перевычислять значения будем также используя только те объекты, которые раньше, чем данный. \textbf{Так делать нельзя!} Когда будет считаться значение $approx$ для последнего объекта, будет использоваться, например, второй объект. При этом будет использоваться $approx$ второго объекта, который, в свою очередь, был посчитан всего по одному значению. Таким образом, качество деградирует. \\
\textbf{Вместо этого – линейное упрощение квадратичной схемы:} используем линейную аппроксимацию квадратичной схемы. \\
Для первого объекта не учим ничего ($=0$). Для второго объекта считается формула на первом объекте. Оценку по градиенту будем считать только на первом объекте. Для третьего и четвертого объекта используется оценка по градиенту при помощи формулы, которая учится на первых двух объектах. Получаем увеличение в 2 раза (этот параметр можно задать вручную), учится $log(n)$ моделей. Хранить нужно линейное количество $approx$’ов. 
\end{itemize}

Такой подход (с упрощением квадратичной схемы) и называется \textit{ordered boosting}. Этот подход хорошо работает на небольших датасетах. В CatBoost автоматически по размеру датасета решается, брать этот метод, или нет. 

\section{Полезный функционал CatBoost}
\subsection{Обучение из бейзлайна}
Можно обучить одну формулу, сохранить ее значения, а затем обучить другую формулу, начиная из сохраненной стартовой точки. \\

Представим ситуацию: допустим, обучили формулу (например, на 1000 итераций) и применили к тестовым данным. Получили значения формулы на каждом документе. После этого обучили вторую половину формулы – еще на 1000 итераций. Это не то же самое, что обучиться сразу на 2000 итераций! \\

Другой результат получается в том случае, если есть категориальные признаки, замененные счетчиками. Когда счетчики считаются на тренировочных данных, для данного объекта обучающей выборки они получаются по его прошлому. Когда модель применяется к данному объекту обучающей выборки, считается, что мы его как бы «приклеили» после всей обучающей выборки. \\

Бейзлайн нельзя использовать для того, чтобы сохранять какие-то промежуточные точки при обучении.

\subsection{Подбор параметров}
Обычно стоит объявлять категориальными только категориальные признаки. Не стоит объявлять все признаки категориальными и думать, что это будет лучше работать. С помощью счетчиков мы пытаемся найти порядок на объектах, чей порядок изначально не задан. В иных случаях эти счетчики уже есть, и их пересчет может вести к снижению точности. 

\begin{itemize}[noitemsep]
\item Один из самых важных параметров – $learning\textunderscore rate$. Чем меньше $learning \textunderscore rate$, тем лучше качество, тем больше итераций градиентного бустинга потребуется. Необходимо постепенно уменьшать этот параметр, пока качество не стабилизируется. 
\item Можно включить детектор переобучения, который сам найдет тот момент, когда перестает улучшаться качество. 
\end{itemize}

Больше всего на качество влияют L2-регуляризация, $random \textunderscore strength$, 
$bagging \textunderscore temperature$ (по умолчанию байесовский bootstrap, можно его подбирать). Увеличение первых двух параметров борется с переобучением. 

\begin{itemize}[noitemsep]
\item \textit{Параметр глубины дерева}: для некоторых датасетов нужна большая глубина (встречаются редко). Уменьшать глубину обычно не нужно. Перебирать глубину по сетке от 1 до 10 не нужно: можно попробовать дефолтные 6 или 10. Обычно этого достаточно.
\item \textit{Размер бинаризации}: ставится отдельно для счетчиков, отдельно – для фичей типа float. Для счетчиков бинаризация равномерная, для float-фичей много разных типов. 
\item $rsm$ – параметр, отвечающий за выбор фичей на каждой итерации. При выборе дерева можно семплировать фичи. В большинстве случаев это не влияет на качество, однако влияет на длину ансамбля. Если фичей мало, нет смысла использовать этот параметр. Если фичей много, можно поставить небольшой rsm. Тогда установленная доля фичей будет каждый раз просматриваться при выборе структуры дерева. Иногда стоит уменьшать этот параметр, если обучение работает очень долго. 
\item \textit{вычисление значений в листьях}: можно делать либо шаг ньютона, ли по градиенту, а также подбирать число шагов. Это не особо влияет на качество.
\item $eval\textunderscore metrics()$ – метод, который можно вызвать у обученной функции на новых данных. Позволяет на каждой итерации посмотреть значение метрики. 
\item $cv()$ – кросс-валидация. Для того, чтобы понять, что кросс-валидация имеет overfit, необходимо отследить ошибку на каждой итерации – это средняя ошибка между всеми фолдами. Overfitting detector будет отслеживать, когда средняя ошибка перестанет улучшаться. 
\item \textit{snapshots} – при запуске метода можно указать библиотеке, чтобы по мере работы сохраняла текущее состояние. Это означает, что при возобновлении обучения оно продолжится с того же места, на котором остановилось.
\end{itemize}

\section{CPU vs GPU}

Имеется реализация алгоритма как на CPU, так и на GPU. При установке через pip скачивается и то, и другое. Если имеется GPU – лучше его использовать, обучение в разы ускорится (до 15 раз). Это делается с помощью параметра $task \textunderscore type="GPU"$. Чем больше датасет, тем больше ускорение – на больших датасетах может достигать 50 раз. \\

Поддерживается несколько GPU, а также несколько серверов с GPU – можно запускать распределенное обучение. \\
 
GPU-обучение быстрее чем LightGBM примерно в два раза, и быстрее чем XGBoost примерно в 20 раз. На больших датасетах CatBoost в 4.5 раза быстрее, чем XGBoost на CPU, и примерно такой же, как LightGBM; на маленьких датасетах примерно в 2 раза быстрее, чем XGBoost, но в два раза медленнее, чем LightGBM. \\

CatBoost стабильно выигрывает у других библиотек по качеству. \\

CatBoost написана на C++, но имеется обертка на Python и R. \\


\end{document}
