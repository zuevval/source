\documentclass[main.tex]{subfiles}
\begin{document}

\section{Лекция 9}

1 апреля 2021 г.

\subsection{Ошибки ML. Анализ качества работы модели}

Мы рассмотрели

\begin{enumerate}[noitemsep]
	\item случаи, когда не нужно применять МО
	\item случаи, когда выбирается неверный путь решения задачи методами МО

	Замечание про балансировку:
	не имет смысл балансировать выборку, в котрой число элементов в классах чуть-чуть различаются.
	Но если не-крокодилов в сто тысяч раз больше, чем крокодилов, то некоторые алгоритмы МО могут плохо научиться распознавать крокодилов.
	Сто не-крокодилов на одного крокодила -- это уже, наверное, ОК.

	Когда классы очень несбалансированные, имеет смысл выбирать в пакетном градиентном спуске примеры из <<редкого>> класса с большей вероятностью, чем из часто встречающегося.

\end{enumerate}

Пусть теперь мы придумали правильную, идеальную модель.
Бывает так, что даже в этом случае мы её не очень хорошо её обучили (не так, как нам нужно).

Например, мы делаем ранжирование крокодилов.
Пользователи будут очень по-разному кликать в зависимости от того, что мы
В офлайн на тестовых данных не всегда удаётся воспроизвести все случаи.

Поэтому часто нужно проводить и онлайн-тесты.

\begin{itemize}[noitemsep]
	\item Собираем две фокус-группы пользователей; даём группе А пользоваться старой моделью, группе Б -- новую и сравниваем метрики (т. н. АБ-эксперименты).
	Если пользователи, которым показали новую модель, показывают, к примеру, больше лояльность к нашему сервису в новой его версии, мы считаем, что новая модель лучше.


	Бывает, что для АБ-экспериментов не хватает данных.
	Например, у сервиса слишком мало пользователей (к примеру, если читать курс в университете по-разному в два разных года, вряд ли можно однозначно считать, что курс был более понятным и интересным в тот год, когда студенты оставили больше хороших отзывов, поскольку могут быть существенные выбросы).

	Данных для АБ-экспериментов не хватает почти всегда (в один из сплитов могут не попасть пользователи из каких-то важных групп).
	Даже в Яндексе, где пользователей миллионы, бывают такие проблемы.
	\item Нельзя слепо доверять АБ-экспериментам, потому что метрики не всегда отражают то, что мы подразумеваем под качеством нашей системы.
	Например, мы считаем метрику <<число кликов на сайте>>, считая, что она отражает заинтересованность пользователя и готовность к нам вернуться.
	Но, может быть, пользователь много кликал на сайте не потому, что ему на нём понравилось, а потому, что неудобный интерфейс (сложно найти необходимые вещи) или мы не выдали сразу нужную страницу (пришлось ещё покликать, чтобы до неё добраться).

	Нельзя сравнивать качество моделей исключительно по матожиданию метрик!
	Данные шумные; если в группе Б за неделю на $ 5\% $ метрики лучше, это может быть обусловлено выбросом.

	Рецепт: делить данные тестов на разные группы (каждый из сплитов А и Б делим ещё на десять групп, т. е. десять пар АБ-экспериментов).
	Если во всех десяти парах матожидание в группе Б больше, наверное, мы дейстительно что-то улучшили.

	На помощь могут прийти статистические тесты (например, Мана-Уитни -- определяет, из одного распределения два набора данных или вряд ли).

	Конечно, на сколько подгрупп делить наблюдения, зависит от того, сколько мы провели экспериментов.
	Статистические тесты, вообще говоря, тоже могут ошибаться (вероятность ошибки зависит от выбранного уровня статистической значимости).

	\item Нужно учитывать распределение данных. % TODO explain a bit?

	Пример.
	Попробуем предсказывать число студентов, ожидающих лекцию перед аудиторией, в зависимости от времени.
	Ожидаем, что за десять минут до лекции вероятнее всего встретить ноль студентов; чем ближе к лекции, тем более матожидание будет смещаться вправо.

	Пусть мы обучили какую-то модель $ f(x) $, кото % TODO x - время ?
	Если штраф за ошибку в каждый момент будет один, то мы будем ошибаться % TODO

	\[ (f(x_{10}) - y_{10})^2 + (f(x_{5}) - y_{5})^2 + (f(x_{0}) - y_{0})^2 \]

	В нашем случае распределение может описываться законом Пуассона.

	Количество лайков под постами в день в зависимости от числа постов тоже описывается пуассоновским распределением.
	Зависимость спроса от цены в некоторых случаях тоже.

	$ \lambda $ -- некая интенсивность (например, иненсивность прихода студентов на лекцию).

	Пуассоновская функция потерь: $ L(f(x),y) = e^y - f(x) \cdot y $.
	Выводится из метода максимального правдоподобия.

	Кроме пуассоновского распределения иногда встречается экспоненциальное.

\end{itemize}

\subsubsection{Ошибки при обучении}

\begin{enumerate}[noitemsep]
	\item Ещё одна распространённая ошибка -- обучать модель <<до упора>>: либо совсем не следить за ошибкой и тем, как мы обучаем, либо не смотреть, в какой момент параметры почти перестают меняться и график ошибок выходит на плато.
	\item Взять совсем неправильные параметры обучения: часто в учебных задачах и соревнованиях данные есть, целевая функция есть, и основная задача -- выбрать хорошие параметры модели.

	Обычно рекомендуется брать такие параметры для градиентного бустинга на деревьев решений: глубина деревьев 6-10

	Параметов обычно очень много.
	Вряд ли имеет смысл пробовать изменять все (например, способ сэмплирования в градиентном бустинге, или подбор порогов) и смотреть, что получится.
	Скорее всего, получится примерно то же, что со стандартными <<разумными>> значениями параметров из коробки.
	Зато, если их как-то бездумно поменять, можно ухудшить нашу систему.

	Сложнее с нейронными сетями, где есть число слоёв и т.д., имеет смысл попробовать разные.
	Но в целом, как правило, больший вклад, чем параметры, вносят данные, вид модели, целевая функция.

	\item Не обращать внимание на логику получаемой модели

	К примеру, если одна модель на тестовых данных даёт AUC 70, другая 80, может случиться так, что в реальном мире первая модель будет работать лучше (напомним, тестовые данные могут недостаточно хорошо отражать реальные случаи применения).

	Полезно проанализировать зависимость ответа модели от значений признаков. Например, мошеннические / не мошеннические операции: если получилось, что вероятность нечестной операции убывает с ростом суммы операции, возможно, мы что-то обучили не так.

\end{enumerate}

\subsection{ Вторая часть лекции. Проект о проверке математических выкладок }

Пусть на вход приходит цепочка математических символов.
Требуется проверить, правильна ли она: с точки зрения теории (например, встречается выражение $ 2 + 2 = 5 $) или переходы не очень понятны / некорректны (например, десять теорем применены за один шаг).

Основная характеристика выражений -- они могут быть сравнены ($ =, \ge, \le $ ).


Пример выражения: $ C(n,k) + n! - k^2 $

\emph{ Факт } есть логическая комбинация выражений.
Два факта могут быть связаны отношением следствия, эквивалентности.


\emph{ Правило } -- возможная трансформация факта или выражения:

\subsubsection{ Подходы к проверке }
\textbf{Нормальные формы}.

Можно ввести нормальную форму, к которой мы будем выражения приводить и к ним применять правила.

Но не для всех выражений можно придумать такие формы!
Для некоторых сложных выражений есть теоремы, которые говорят, что алгоритмически их сравнить нельзя.

Можно построить \emph{ граф преобразований }: все выражения -- вершины, преобразования между ними -- рёбра.
Граф бесконечный, он генерируется из правил прямо в процессе работы алгоритма.
Например, из вершины $ 2 \sin(x) \cos(x) $ есть переход в $ \sin(2x) $.
Тогда задача сводится к проверке наличия пути между двумя вершинами.
Если пути нет, выражения $ A $ и $ B $ не равны; может быть, путь есть, но он слишком сложный (чересчур много рёбер).

Как эффективно искать путь в графе?
Можно поиском в ширину из каждой вершины.
Но количество обходимых вершин экспоненциально возрастает с ростом числа ярусов обхода; впрочем, здесь нам помогает ограничение -- мы не проверяем слишком сложные выражения (для которых надо пройти по рёбрам слишком длинный путь).

Возможны оптимизации.
Например, некоторые преобразования выражения $ R $ могут уводить совсем в другую сторону от выражения $ L $.
Можно попытаться определять расстояния между вершинами и следить за тем, чтобы вершины, в которые мы приходим из вершины $ R $, были ближе к $ L $, чем $ R $, или ненамного дальше (алгоритм $ A^* $).
Это эвристический алгоритм.

Много тонкостей!
Например, некоторые выражения можно применять только в одну сторону (умножение на ноль).
Есть преобразования, которые мы привыкли применять за один переход (например, коммутативность, ассоциативность при сложении).
Система эффективно перебрать такое число преобразований не может.

\textbf{Метод тестирования:}

присваиваем переменным символьные выражения и пытаемся сравнивать, подставляя конкретные значения.

Для проверки эквивалентности двух равенств: можно искать точки, в которых выражеия савнимы; переходить в комплексную область при выходе за область определения (к примеру, проблема -- для выражений $ \sqrt{x - 1001} $ и $ \sqrt{ -1002 - x } $ трудно найти точки на вещественной прямой, где они вместе определены).
Фиксировать голоморфные ветви логарифмов при вычислении.
Впрочем, фиксирование голоморфной ветви не всегда решает проблему.
Например, при $ x \in \mathds{R} $ есть правило: логарифм произведения есть сумма логарифмов.
В комплексных числах
\[ \ln \left( \prod_{j=1}^{n} z_j \right) = \sum_{j=1}^{n} \ln (r_j) + i \left( \sum_{j=1}^n \phi_j - 2 \pi k \right) \]

Кажется разумным сравнивать числа с точностью до периода комплексной части $ 2 \pi $, но преобразование может быть внутри других выражений, и тогда это не работает.
Решение: можно проводить несколько тестов и считать, что, если совершено $ n $ преобразований с логарифмами, должны быть пройдены приблизительно $ \frac{1}{n!} $ тестов.

Другая проблема: какие преобразования можно производить за один шаг и в каком количестве?
Например, в системе уравнений удобно и логично за один шаг сделать перестановки в нескольких уравнениях. \\

Проверка неравенств:
поиск точек, в которых они нарушаются.

Не очень понятно, как искать такие точки.
Решение: рассматриваем разность и частное наших выражений и минимизируем (комбинация градиентного спуска и случайного отжига).

Пример: сравниваем $ e_1(x) \overset{?}> e_2(x) $ $ \Rightarrow $ минимизируем $ e_1(x) - e_2(x) $ или  $ \frac{e_1(x)}{e_2(x)}  $.
Конечно, при этом можно попасть в локальный минимум или прийти в точку, где выражение не определено.
Если выражение не определено в вещественной области, можно перейти в комплексную и минимизировать комплексную часть.

Какое начальное значение при минимизации выбрать?
Нужна какая-то эвристика для приблизительного определения интервала, в который попадают точки.

\subsubsection{ Аналоги }
Wolfram, SymPy -- там тоже, к примеру, реализован метод тестирования.
Но они ориентированы в основном на вывод решения задачи, а не проверку.


\end{document}
