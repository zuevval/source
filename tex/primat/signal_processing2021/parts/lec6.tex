\documentclass[main.tex]{subfiles}
\begin{document}

\subsubsection{}

Напомним, мы остановились на слайде с примерами целевых функций.

\emph{Целевая функция}: есть задача, которую хотим решить; есть модель с параметрами, которые хотим подобрать.
Модель с параметрами, значения которых мы подберём, должна хорошо описывать наши обучающие данные.
Для этого мы строим функцию, которая минимизирует ошибку на данных (мы надеемся, что не только на наших данных, но и на тех, которые придут после обучения).

Обучили модель $f(x, \omega) \in F$ ($\omega$ -- параметры, $F$ -- семейство функций со всевозможными $\omega$).
Задача: найти $\omega_{opt} : f(x_i, \omega_{opt})$ минимизирует ошибку.

Бывают различные функции:

\begin{enumerate}[noitemsep]
	\item Разностные $L(y, f) = \frac{(y-f)^2}{2} $, $ L(y,f) = |y-f|  $
	\item Иные, например, $ \exp{-yf} $
\end{enumerate}

Целевую функцию нужно подбирать в зависимости от задачи, например, если данные распределены по закону Пуассона, нужна некоторая особая функция.

\subsubsection{Как выбирать признаки (features)}

Будем рассматривать пример классификации операций на мошеннические и не-мошеннические.
Признаки: дата операции, сумма, ... (числовые признаки)

Составим таблицу:

% TODO

Можем эти признаки складывать, сравнивать.

\subsubsection{Категориальный бустинг CatBoost}

Бывают признаки не только числовые, но и категориальные (например, профессия человека).
Как с ними работать?

Идеи, которые не работают:
\begin{enumerate}[noitemsep]
	\item Присвоить каждой категории номер (плохо, т. к. у числовых признаков есть естественный порядок, а здесь он будет искусственный).
	\item Если мы строим дерево решений, разветвлять в узле не на два, а по числу категорий. Но тогда, если, скажем, у дворников до сих пор не было мошеннических операций, дерево может обучиться так, что все операции дворников будут считаться не мошенническими.
	\item one-hot-encoding (по каждой из профессий делаем разветвление, например, дворник и все остальные): работает неплохо, но не учитывает связность признаков. 
\end{enumerate}
 
Идеи, которые работают:

\begin{enumerate}[noitemsep]
	\item Кодируем значение признака статистикой по значению:
	\begin{enumerate}[noitemsep]
		\item Эмпирической вероятностью, то есть долей в выборке (например, считаем, сколько в данных дворников, сколько программистов и так далее).
		Но мы теряем информацию: вместо характеристики <<дворник>> у нас число / доля дворников.
		\item С использованием цлеевой функции: среднее значение целевой функции. может привести к переобучению % TODO explain in details
		\item Как в предыдущем случае, но сортировать или не сортировать % TODO
		
		Убережёмся от случая, когда дворники в обучающей выборке совершали слишком мало мошеннических операций.
		
		С ходу кажется, что лучше не сортировать, но ведь можно и 
	\end{enumerate}
\end{enumerate}

Такие <<продвинутые>> способы кодировать категориальные признаки реализованы только в библиотеке CatBoost.

\begin{leftbar}
	Отступление.
	Нужно ответственно относиться к выбору фич. % TODO 
\end{leftbar}

\subsection{Основные методы машинного обучения}

\subsubsection{SVM}

Распространённый миф: <<SVM работает только для линейно разделимых данных>>.
На самом деле в случае не разделимых линейно классов можно перейти в пространство более высокой размерности.

\subsubsection{Оценка по ближайшим}

Рассматриваем точки (обучающую выборку) в пространстве признаков.
Это не обязательно $n$-мерное линейное пространство, могут быть заданы только расстояния (граф).

Идея: когда приходит новая точка, для которой нужно определить класс, ищем $k$ ближайших соседей

Минус:

\begin{enumerate}[noitemsep]
	\item нужна понятная метрика расстояния.
	Как, например, считать расстояние для категориальных признаков?
	\item Метод медленный (надо считать расстояние до всех точек, чтобы определить $k$ ближайших).
\end{enumerate}

\subsubsection{Деревья решений}

В узлах вопросы <<Да/нет>>.
В листах признаки.

Как обучать?
Проблема: какой признак должен быть ближе к корню дерева?
К примеру, в самом первом узле нужно разделять по сумме операции, по валюте или по времени суток?

Другие вопросы: как подобрать
\begin{enumerate}[noitemsep]
	\item порог, по которому разделяем
	\item максимальную глубину дерева
\end{enumerate}

Для того, чтобы ответить на эти вопросы, нужно уметь оценивать разбиения.
Например, есть такая целевая функция, как \emph{энтропия Шеннона}:

$$ S = - \sum_{i=1}^{N} p_i \log_2 p_i $$

Поэтапно строим дерево, пока оно не описывает данные достаточно хорошо (например, пока энтропия достаточно велика).
Но нужно вовремя остановиться, чтобы не было переобучения.
Как правило, останавливаются ещё в тот момент, когда в узлах есть примеры с разными метками.

Подбор порядка признаков: сложный вопрос, в разных библиотеках реализовано по-разному.
Общая идея: признак выбирается случайно или почти случайно; повторяем построение несколько раз и выбираем лучшее. \\

Деревья можно объединять в ансамбли (например, градиентным бустингом).
В этом случае имеет смысл брать от ответа некоторую масштабирующую функцию (например, сигмоида), чтобы ответ ансамбля лежал в пределах от 0 до 1.

\subsubsection{Марковские модели}

Классическая ММ: вероятность перехода в следующее состояние зависит только от текущего состояния.
Существуют и иные, где вероятность зависит от нескольких предыдущих состояний.

\subsection{Часть 2 лекции}

\subsubsection{Вспоминаем дерево решений}

Дерево решений строит классификатор по поданным на вход признакам, но не комбинирует их.

Пример: если классифицируем предложения магазинов, разумно учитывать признак <<число отзывов>>.
Но если брать признак в сыром виде, получится, что у одного магазина 10, у другого 100 и у третьего 1000 отзывов, поэтому может быть разумно взять логарифм.
Дерево решений само это не сделает.

Или, может быть, разумно взять сумму, разность или иное преобразование от признаков.
Это характерно для изображений (брать сумму/разность соседних пикселей; сглаживающие фильтры).

Дерево не может автоматически подбирать значения параметров фильтров.

\subsubsection{Подбираем значения параметров}

Рассмотрим простейший детектор границ.

Пусть мы сворачиваем пиксели фильтром с параметрами $\omega_1, \omega_2, \omega_3$ (новые признаки -- суммы соседних пикселей с этими весами); затем это сворачиваем с ещё одним фильтром, а дальше берём значение по порогу: если больше порога, в соответствующей области есть граница.

Это уже похоже на нейронную сеть -- т. н. \emph{свёрточная} НС (основанная на операции свёртки), она же CNN (convolutional neural network).

\subsubsection{Pooling layer}

Слой пулинга берёт какое-то преобразование от картинки, уменьшая число пикселей % TODO
Это может объясняться необходимостью масштабирования (вспомним детектор Харриса).

Итак, есть свёрточные слои, слои пулинга и слой активации (последний), выход которого мы сравниваем с порогом (в этом слое может быть, например, сигмоида).
Полуаем модель алгоритма с параметрами.
Подбор архитектуры (порядка и состава слоёв -- творческий процесс).
Модель содержит множество параметров.

Возможна такая интерпретация: конечные слои нейросети -- дерево решений, а все предыдущие слои -- подготовка признаков на основе исходных данных. \\

Deep Learning переводится как <<глубокое обучение>> или <<глубинное обучение>>.
Иногда этими двумя терминами называют разные вещи: глубинное -- каждому признаку присваивается свой смысл (например, поиск у котика усов, глаз...), глубокое -- просто множество параметров, которые обучаем.
Мы не будем различать эти две вещи. \\

Свёрточные нейронные сети беспрецедентно хорошо работают на изображениях, что многократно подтверждено на практике.
Есть соревнование ImageNet, которое в 2012 году выиграла сеть AlexNet, и с тех пор год от года выигрывают только CNN.

Нет никаких оснований верить, что CNN будут одинаково хорошо работать во всех случаях!
Впрочем, если данные организованы похожим на изображения образом, можно попробовать.
Можно комбинировать нейросеть с деревом решений и так далее.

\subsubsection{Свойства нейронных сетей}

НС -- модель, представимая в виде обобщённого графа вычислений.

НС работают быстро.

При обучении надо помнить, что структура не должна включать слишком много параметров, иначе не получится градиентным спуском подобрать разумные значения.

\subsubsection{Обратное распространение ошибки и градиентный спуск}

Обучение осуществляется алгоритмом обратного распространения ошибки:
подаём на вход обучающий пример $ \Rightarrow $ % TODO a bit

Важно понимать, какая механика под этим лежит.
Алгоритм обратного распространения ошибки (backpropagation) -- реализация градиентного спуска. \\

Пусть есть функция потерь $ L(\omega) $, которую мы минимизируем: $ L(\omega) \to \min $.

Градиентный спуск: пересчитываем вектор $\omega_k$, $k$ -- номер итерации.  
$$ \omega_{k+1} = \omega_k + \alpha_k \nabla L(\omega_k), \alpha_k : L(\omega_{k+1}) \to \min_{\alpha_k} $$

Проблема градиентного спуска: если оси неравномерно масштабированы (функция потерь \emph{овражная}), будем спускаться медленно.
Чтобы бороться с проблемой, испольюуют, к примеру, метод Ньютона (хорошо работает для квадратиных форм). \\

Минимизируемая функция $L$ есть сумма большого числа слагаемых (ошибок).
$$ L(\omega) = \sum_{i=1}^{N} \tilde L (y_i, f(x_i, \omega)) $$
Градиент этой функции
$$ \nabla L(\omega) = \frac{1}{N} \sum_{i=1}^{N} \nabla \tilde{L}(y_i, f(x_i, \omega)) $$

Вычислять этот градиент на каждой итерации обучения дорого, если обучающих примеров много.
Поэтому используют \emph{стохастический градиентный спуск}: делают шаг не в направлении полного градиента, а используют лишь случайную часть выборки (mini-batch).
$$ \omega_{k+1} = \omega_k - \alpha_k \frac{1}{|I_k|} \sum_{i \in I_k} \nabla_i \tilde L (y_i, f(x_i, \omega_k)) $$

Стохастический градиентный спуск может плохо вести себя в окрестности оптимума (блуждать).
Чтоб это смягчить, можно $\alpha_k$ к концу обучения уменьшать. \\

Когда остановиться?
Можно до тех пор, пока не перебрали все элементы в обучающей выборке.
Можно следить за статистиками и при каком-то пороге прекращать.
Или просто обучаем и обучаем месяцами, время от времени проверяя, не получилось ли что-то хорошее.

\end{document}
