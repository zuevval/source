\documentclass[main.tex]{subfiles}
\begin{document}

\section{Лекция 4. Введение в машинное обучение. Основные используемые методы}
25 февраля 2021 г.

\subsection{О большой лабораторной}

\subsubsection{Замечания о постановках задачи}

Примеры ошибок:

\begin{itemize}
	\item Гитара:
	\begin{itemize}[noitemsep]
		\item <<Бинаризуем гитару>>:
		Надо написать принцип, по которому будем подбирать значения порогов (например, так, чтобы в выделенную часть попадала только гитара).
		Если не получится, попробую применять бинаризацию не к чёрно-белому изображению, а, к примеру, к зелёному каналу и т. п.
		\item <<Найти разность крайних проекций на каждую ось, тем самым узнав размеры гитары в пикселях>>.
		Что такое оси?
		Как их находить (из окружения - пол, стены)?
	\end{itemize}
	
	\item Дверь:
	
	\begin{itemize}[noitemsep]
		\item <<С помощью алгоритма sift найдём особые точки двери>>: SIFT не ищет особые точки, надо по шагам написать, как будем искать.
		\item <<По их координатам определяем размеры>>: стоит написать, как именно находим по координатам размеры (ведь могут быть искажения, может быть даже непонятно, какая ориентация).
	\end{itemize}
	
	\item Хорошая фраза при решении задачи о столе и стуле: <<предположим, что свет под стол не попадает и щель тёмная>>
	
\end{itemize}

\subsubsection{Как нужно на самом деле}

Есть изображение (матрица пикселей), от которой надо перейти к признакам.

Две основные ветки решения задачи: 

\begin{enumerate}
	\item поиск границ (Canny и т. п)., у Canny много параметров (фильтры, $\sigma$, пороги...) -- либо брать произвольные, либо как-то подбирать.
	
	Далее можно искать какие-то геометрические примитивы (например, преобразованием Хафа).
	Можно и другие критерии, но для большинства примитивов, наверное, преобразование Хафа -- оптимальный вариант.
	Более сложные можно искать по шаблонам и т. д.
	
	Далее, найдя примитивы, получаем какие-то признаки.
	\item Вторая разумная схема -- идти через особые точки.
	Сбор дескрипторов, сбор словаря особых точек по изображениям, которые есть в датасете (обучение особых точек).
	Далее -- распознавание и идентификация особых точек.
	
	\item Можно включить много разных идей (бинаризацию и т. д.), но два описанных выше -- основные.
\end{enumerate}

При поиске особых точек: есть точки, которые мы нашли; есть те, которые мы ожидаем (к примеру, шесть дескрипторов).
Что теперь делать? Хотим из тех, что нашли, отобрать наиболее похожие на ожидаемые.
Можно посчитать какое-то расстояние между дескрипторами; если оно меньше какого-то порога, 
Но может оказаться, что не всегда получается понять, какая из точек соответ
Тогда надо использовать геометрические соответствия (например, прямые, проходящие через особые точки)

В конце получается таблица преобразованных признаков $ p_1, p_2, ... $; какая-то таблица с номерами объектов; и надо решать, с какой вероятностью найденный объект с найденным набором признаков похож на то, что мы ищем (может быть простой критерий, может быть более сложный).

Если же мы не ищем особые точки, а делаем преобразование Хафа: обучать прямые на изображении можно, но, наверное, разумнее глазами посмотреть на картинки из датасета и понять, какие есть соотношения между прямыми.

Вторая, наиболее сложная часть задачи, -- подобрать критерии разумным образом.

Третья часть: поняли, что стул -- это стул, стол -- это стол; теперь надо сориентировать их в пространстве.
Можно попытаться сравнить их размеры. Более разумная идея -- найти доминирующую ось (наверное,)
Можно было бы применить преобразование гомографии, которое поможет исправить перспективные искажения, но для этого нужно идентифицировать на фотографии объект, размеры которого мы знаем точно.
Наверное, разумно пока что брать какие-то усреднённые размеры по длинам рёбер на изображении, если не получится, думать, как улучшать алгоритм.

\subsubsection{Организационные детали}

Предлагается составить набор советов по решению большой лабораторной (список советов, список ошибок...)

\begin{leftbar}
	За это даются баллы.
	
	Можно прислать по ходу курса, можно где-то в конце.
	
	Возможно, будет составлена форма.
\end{leftbar}

\subsection{Машинное обучение. Введение}

\subsubsection{Заметка о статистических методах на предыдущих лекциях}

Мы узнали методы, которыми мы как-то описываем происходящее на изображении (вот прямые, вот границы, примитивы...) и строим критерий (функцию), которая как-то решает задачу.

Т. о. это модель с параметрами, которые мы как-то подбираем.
Много вещей, которые могут быть разными; нужно подбирать, находить оптимальный порядок преобразований и параметрами.

Понятно, что параметров не должно быть много (иначе не справимся с подбором).
Даже если их мало, сложно вручную подобрать оптимально.

Хочется что-то автоматизировать $ \Rightarrow $ приходим к идее машинного обучения.

\subsubsection{Задача машинного обучения}

У нас есть данные, которые содержат необходимые сведения об объекте; хотим загрузить их в <<волшебную машину>>, которая бы как-то находила изображения, похожие на то, что у нас в наборе.

Обучающая выборка: набор векторов признаков $ \{x_i\} $ (например, картинка из 256 пикселей, возможно, содержащая крокодила); нужно сконструировать функцию $ y=f(x) $ от вектора признаков, которая научится вычислять по набору признаков искомое значение $y$.

\subsubsection{Статистические основы}

В идеальном мире считаем, что генеральная совокупность описывает все примеры, которые могут встретиться.

Имеем дело с выборкой из генеральной совокупности.
Часто важно распределение данных.
Распределение target function: не всегда нормальное.

\subsubsection{Задачи ML}

\begin{enumerate}[noitemsep]
	\item \textbf{Классификация:} есть набор данных, у которых известны классы.
	Хотим узнать, к какому классу принадлежит экземпляр данных, который приходит на вход (более общая формулировка: с какой вероятностью принадлежит входной объект каждому из классов).
	\item \textbf{Регрессия:} дана выборка $ \{ (x_1, y_1), ..., \} $; пытаемся аппроксимировать зависимость $ y(x) $.
	\item \textbf{Кластеризация:} хотим разбить на классы, но не знаем, на какие.
	Имеет много разновидностей.
	Стоит особняком от всех остальных задач ML.
	Не очень понятно, как оценивать качество кластеризации.
	\item Остальные задачи (их много): пример -- задача о парах (понять, какой из двух пришедших элементов должен идти первым, какой вторым).
	Задача о ранжировании результатов поиска: 
\end{enumerate}

\subsubsection{Решающий модуль и алгоритм}

\emph{Решающий модуль} -- алгоритм, решающий задачу.

\emph{Разумный решающий модуль} -- алгоритм, который решает задачу лучше, чем алгоритм случайного угадывания ответа.
Как-то комбинируя разумные решающие модули, можно создать алгоритм машинного обучения.

\subsubsection{Классификация и регрессия}

Есть семейство алгоритмов $ F $, из которого хотим выбрать один алгоритм $f$.
Для этого вводим функционал от ответов на обучающей выборке (\emph{функция потерь}), минимизируя который (по параметрам $f$), получаем результат.
Это может быть сумма квадратов разностей.

Важно, что мы не можем оценить качество работы на всей генеральной совокупности.
Отталкиваемся от выборки (\emph{эмпирический} риск: $ R_{emp}(f, x^m) = \frac{1}{m} \sum_{i=1}^{m} L(f(x_i), y_i) $).
Поэтому часто параметры выборки имеют большее значение, чем решающий алгоритм.

Нюансы:

\begin{enumerate}[noitemsep]
	\item Возможна неоднозначность решения (много гипотез, имеющих нулевой функционал риска).
	\item Возможно \emph{переобучение}: воспроизводим ту зависимость, которая хорошо работает на обучающих данных, а на остальных -- плохо.
	Чтобы этого не произошло, надо брать данные для контроля.
	Впрочем, часто данных не хватает, хочется побольше данных взять и для обучения, и для тестирования...
	Ещё способ бороться с переобучением -- не брать модель со слишком большим числом степеней свободы (например, полином большой степени).
	
	Теория (Вапник, Червоненкис): есть данные для обучения и тестирования; обучаем алгоритм до тех пор, пока ошибка убывает и на тех, и на других данных.
	Когда ошибка на контрольной выборке начинает возрастать, надо остановиться.
	
	Есть критерии того, насколько много данных нужно, чтобы разумно обучить $ N $ параметров.
	Например, на датасете из ста изображений вряд ли получится обучить нейронную сеть с миллионом параметров.
\end{enumerate}

\subsubsection{Оценка результатов. Кросс-валидация}

Часто данных мало, и опасно выбросить часть данных и сказать: <<вот данные для тестирования, мы их для обучения не используем>>.

Делим выборку на $d$ непересекающихся частей и будем по очереди использовать только одну часть для тестирования, остальные для обучения.
Тем самым мы уменьшаем вероятность того, что в данных будет присутствовать закономерность, которую мы не используем для обучения.

"5-2 cross-validation":

\begin{enumerate}[noitemsep]
	\item Разделим выборку случайным образом пополам
	\item Обучим на одной половине, протестируем на другой, затем наоборот
	\item Повторим 5 раз и усредним результат
\end{enumerate}

\subsubsection{Общие ошибки алгоритма, которые надо учитывать}

Ошибки I и II рода:

\begin{enumerate}[noitemsep]
	\item I -- считаем, что экземпляр принадлежит побочному классу, когда в реальности -- основному, т. е. False Negative.
	\item II -- в реальности к побочному, а мы относим к основному: False Positive.
\end{enumerate}

Есть множество других ошибок.
ROC-кривая (Receiver Operating Characteristic Curve): оси <<чувствительность>> -- <<избирательность>>

\emph{Чувсивительность} -- вероятность дать правильный ответ, когда экземпляр принадлежит основному классу.
\emph{Избирательность} -- вероятность

Площадь под графиком -- AUC (area under curve).
Пространство разумных алгоритмов лежит где-то выше прямой, идущей из угла в угол (случайное угадывание).

Точка в левом верхнем углу -- идеальный результат, в правом нижнем -- все ответы неверные.

\subsubsection{Использование имеющихся данных}

\begin{enumerate}
\item Кросс-валидация

\item Bagging:
\begin{enumerate}[noitemsep]
	\item генерируем по нашей большой выборке более мелкие (сэмплируем из равномерного распределения номер элемента в большой выборке, причём берём элементы с возвращением)
	\item на каждой сгенерированной выборке обучаем свой решающий модуль
	\item результирующий модуль агрегирует результаты всех модулей
\end{enumerate}

\item Можно результаты разумно группировать.
Например, при ранжировании результатов поиска можно группировать ссылки по пользователью или запросу.

\item Можно концентрироваться на сложных (как правило, отрицательных) экземплярах, чтобы алгоритм лучше научился их определять.

\item Если данных очень много и они охватывают почти всю генеральную совокупность (например, нашли все изображения крокодилов): можно упростить алгоритм вплоть до поиска по шаблонам.
Существуют алгоритмы, которые по фоторгафии вида из Европы довольно точно определить, в каком городе снято.
\end{enumerate}

\subsubsection{Схема использования}

Что у нас есть в задаче МО?

\begin{enumerate}
	\item Выбор модедли:
	
	Данные + задача + чувство прекрасного, которое говорит нам о том, какое решение задачи <<хорошее>> и какое <<плохое>> $ \Rightarrow $ раздумья $ \Rightarrow $ данные для оучения + данные для тестирования + модель (семейство решающих функций), а также метод оптимизации и критерий.
	
	\item Обучение
	
	Получаем обученный решающий модуль (или набор обучающих модулей).
	Если на этапе тестирования получается плохой обучающий модуль, переходим обратно к раздумьям.
	Иначе следующий этап -- применение.
	
	\item Применение
	
	Пользователь может пожаловаться и вернуть нас на этап раздумий.
	Например, могут обнаружиться баги в библиотеке.
\end{enumerate}

Чем дальше мы обнаруживаем ошибку на этом пути, тем тяжелее её исправлять.

\subsection{Бустинг}
\subsubsection{Комбинирование решающих модулей}

Можно случайно обучать модули и как-то агрегировать результаты и т. д.

Есть эффективная схема -- \emph{бустинг}.
Решающие модули, как правило, разумные (решают лучше, чем монетка).
Хотим их комбинировать.

Идея: обучили модуль $ f_1 $, который решает задачу с ошибкой $e_1$.
В итерации обучаем следующий модуль $f_i$, взяв с большим весом те данные, на которых ошибается предыдущий.
Желательно: $ e_i \to 0 $
Общий решающий модуль составляется как комбинация всех полученных $f_i$.

\textbf{Градиентный бустинг}: будем понимать градиент как разностные производные.
Тогда мы спускаемся по граденту эмпирического функционала риска $L$ в пространстве параметров семейства $ F $.

Хорошо работает комбинация бустинга и бэггинга.

\subsubsection{Градиентный бустинг}

Финальный решающий модуль -- линейная комбинация решающих модулей: 
$$ F_M(x) = \sum_{m=1}^{M} b_m h(x;a_m), b_m \in \mathds{R}, a_m \in A $$

Есть множество решающих функций, которые используются в бустинге.

\end{document}
