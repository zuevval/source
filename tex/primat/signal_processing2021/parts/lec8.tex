\documentclass[main.tex]{subfiles}
\begin{document}

\section{Лекция 8. Задачи, для которых нужно много данных. Распознавание лиц }

На прошлой лекции мы рассмотрели ситуации, когда машинное обучение применяется, хотя применять его не нужно.
Сегодня рассмотрим ситуации, когда машинное обучение применять хорошо, но оно применяется неверно (и когда это можно определить с самого начала, после чего исправить).

\subsubsection{[Ошибки ML] Неправильная модель / данные / цель }

\begin{enumerate}[noitemsep]
	\item Модель не соответствует смыслу задачи
	
	Если данные описываются какой-то зависимостью, разумно брать такую же или похожую модель.
	Не нужно просто брать какую-то модель просто потому, что она есть в библиотеке.
	
	Например, если мы классифицируем банковские операции (мошеннические / не мошеннические), то линейная регрессия (складываем с разными коэффициентами сумму и валюту операции, а также другие факторы) вряд ли имеет смысл.
	Нейронные сети тоже не стоит применять (НС лучше, когда много похожих признаков -- например, пиксели в изображениях).
	
	\item Модель содержит слишком много параметров: на имеющихся данных столько не обучить
	
	Допустим, нашли модель, которая должна хорошо описывать ситуацию.
	В мире много вещей, которые мы не знаем.
	Начинаем добавлять параметры (слои нейросети и т. д).
	Притом данных зачастую не очень много $ \Rightarrow $ скорее всего, модель будет переобучаться (будет множество ситуаций, которые хорошо описывают наши данные, но многие из них, вероятно, неверно описывают реальный мир).
	Если мы обучаемся и видим, что что-то идёт совсем не так, вероятно, можно попробовать упростить.
	Грубо говоря, если задача плхо приближается полиномом третьего порядка, попробуйте полином второго порядка.
	Как считает Виктор Игоревич, для хороших данных разумно брать число параметров $ < \frac{\text{число примеров}}{10} $,
	для неточных данных в знаменателе $ 1000 $.
	
	\item Взять все имеющиеся данные без предобработки
	
	Если возьмём все исходно пришедшие данные, возможно, система МО получится не такая хорошая, как если мы их предварительно отфильтруем и/или кластеризуем и так далее.
	\item Целевая функция решает не ту задачу
	
	Часто сложно смоделировать функцию, которая будет описывать то, что нужно.
	Например, как понять, насколько хорош результат поискового запроса в интернете?
	
	Особые случаи: предсказание вероятности -- как предсказывать вероятность (к примеру, вероятность того, что на картинке крокодил)?
	Идея: надо целиться в logloss 
	$$ \frac{-\sum_{i=1}^{N}w_i(c_i log(p_i) + (1-c_i)log(1 - p_i))}{\sum_{i=1}^{N} w_i}  $$
	
	Иная ситуация: допустим, у нас есть несколько подгрупп крокодилов, и мы выдаём результаты поискового запроса.
	Хотим, чтобы из каждой группы выдавались последовательно по одному представителю (например, крокодил на белом фоне, крокодил в Африке, ...), а не сперва 1000 крокодилов на белом фоне.
	Для этого существуют \emph{ранжирующие метрики}, например, QuerySoftMax: 
	$$ \frac{\sum_{Group \in Groups} \sum_{i \in Group} w_i t_i \log\left( \frac{w_i e^{\beta \alpha_i}}{\sum_{j \in Group} w_j e^{\beta a_j} } \right)}{\sum_{Group \in Groups} \sum_{i \in Group} w_i t_i} $$
	
	Таких метрик много.
	QuerySoftMax -- на выходе не вероятности, а что-то гораздо больше (годятся именно для задачи выбора из группы).
	QueryCrossEntropy -- ближе всего к logloss.
	
	Все эти метрики уже поддерживаются в CatBoost.
	
	\item Неправильный подбор целевых меток
	
	Не нужно устанавливать метки класса <<крокодил>> у бегемотов.
	
	В задаче с результатами поисковой выдачи есть эвристические метрики наподобие <<если пользователь долго находился на странице и много кликал, страница ему интересна с высокой вероятностью>>.
	
	Ещё пример: у нас интернет-магазин и мы предоставляем пользователю право выбрать службу доставки.
	Хотим выбрать хорошие службы доставки, и в качестве целевой функции берём качество доставки: если пользователь выбрал службу, ей прибавляем 1, иначе 0; если 
	
	\item Попытка сбалансировать выборку
	
	Балансировка выборки, к примеру, бывает такая: если надо распознавать крокодилов, подавать на вход равное число экземпляров с крокодилами и не с крокодилами.
	Так можно сделать, но нет смысла!
	
	Если объектов одного класса намного больше, чем другого, мы просто выкидываем часть данных, которые могли бы помочь в обучении модели.
\end{enumerate}

\subsection{Распознавание лиц}
В задаче распознавания лиц есть как минимум три разновидности:

\begin{enumerate}[noitemsep]
	\item Обнаружение лиц: есть ли лицо на изображении?
	\item Локализация: обвести лицо квадратом.
	\item Понять, принадлежат ли выделенные лица одному и тому же человеку (возможно, также определить, чьё это лицо -- тут нужна база данных лиц).
\end{enumerate}

Обнаружение лиц (с целью привлечения внимания при появлении лица): возможно, здесь не так страшно, если будет немного false positive; часто нужно в реальном времени.

Локализация лиц: тут хорошо бы, чтобы камера фокусировалась на лице.

\subsubsection{Распознавание лиц: идеи}

Допустим, есть много данных (лиц) и мы знаем, какой алгоритм хорош.
Что делать?

\begin{enumerate}[noitemsep]
	\item Поиск характерных черт лица -- особые точки (для глаза -- зрачки, уголки глаз), особые области (иногда можно выделить характерный эллипс глаза)
	\item Цвет, затенение (участки глазниц обычно светле, чем часть под бровями)
	\item Текстура кожи (скорее всего, по текстуре лучше, чем по цвету)
\end{enumerate}

\textbf{ Здесь начинается часть 2 лекции }.

\subsubsection{Нейронные сети}

Допустим, мы хотим распознавать лица нейронными сетями.
Во что можем целиться, какие признаки получать?

Допустим, есть особые точки; хотим, чтобы нейронная сеть научилась по найденному множеству особых точек выдавать ответ о лице.
Можно попробвать научить нейронную сеть решать задачу регрессии: по особым точкам найти координаты лица.

\subsubsection{Elastic graph matching}

Можно по особым точкам строить граф; весами рёбер могут быть расстояния между вершинами.
Потом искать граф в базе.

Такие алгоритмы часто использовались раньше, когда не так были популярны нейронные сети.
Нейронную сеть дольше обучать, но быстрее применять.

\subsection{Детектор Viola-Jones}

\subsubsection{ Детектор лиц Viola-Jones. Сканирующее окно }

\begin{enumerate}[noitemsep]
	\item Выбираем размер сканирующего окна (например, $ 24 \times 24 $)
	\item Проходимся окном по изображению и ищем признаки
	\item Повторяем так для разных масштабов, притом всякий раз приводим к картинке $ 24 \times 24 $
\end{enumerate}

Будем использовать градиентный бустинг для поиска лица в окне.
Понятно, что напрямую использовать пиксели для построения дерева решений нехорошо: фичи -- конкретные пиксели, пиксель может быть зашумлён (нужно хотя бы сгладить); к тому же, на лице много линейных зависимостей, которые мы не учитываем.
Например, выделяем область, в которой, как предполагаем, есть область под и над глазами; сравниваем интенсивности в них.
Если лицо на картинке есть, область с глазами, вероятно, намного темнее.

\subsubsection{Использование интегрального изображения для поиска признаков}

Чтобы считать признаки вида <<разность яркостей в чёрной и белой областях>>, нужно вычислять суммы интенсивностей пикселей в областях.
Каждый раз это делать долго, поэтому строим \emph{интегральное изображение}: в каждой ячейке -- сумма интенсивностей пикселей, которые левее и выше его.
Тогда интенсивность в прямоугольнике можно вычислить за 3 операции сложения.

Прямоугольные признаки лучше, чем просто интенсивности в пикселях (не сравниваем с порогом, а сравниваем интенсивности в тёмной и светлой областях).

\subsubsection{Детектор Viola-Jones. Применение: окно + признаки }

Как обычно, строим слабые классификаторы на основе интегральных признаков, каждый из которых решает задачу немного лучше монетки; реализуем градиентный спуск в пространстве слабых классификаторов.

\subsubsection{Детектор Viola-Jones. Каскадная модель сильных классификаторов}

Когда стали применять детектор Viola-Jones, оказалось, что он классифицирует с точностью примерно 0.95, но это на одном окне.
Но если мы проходимся окном по изображению, 0.95 уже мало для множества окон.

Идея: вначале отфильтровать окна, которые точно лицо не содержат.
Затем обучить ещё один классификатор, который будет отличать лица от того, что похоже на лица, но лицами не является.

Эта идея похожа на градиентный бустинг, только в градиентном бустинге мы складываем полученные деревья, здесь же просто последовательно применяем к окнам первый классификатор, затем к подмножеству окон, которые, возможно, содержат лицо -- второй классификатор.

\subsection{Eigenfaces}

Eignefaces -- старый алгоритм поиска лиц в базе.

Считаем, что исходно лица находятся в пространстве признаков очень большой размерности (пиксели), надо понизить размерность.
Идея: применяем PCA; ожидаем, что останется только несколько основных векторов.

Например, пусть в выборке $ n $ изображений $ m \times k $.
Вначале нормируем данные в выборке, затем строим из каждой картинки вектор $ m \times k $ и ищем матрицу ковариации.

У полученных данных есть несколько собственных векторов (каждый собственный вектор будет примерно похож на лицо, самые первые, самые большие собственные векторы приблизительно ортогональны).

Взяв несколько первых главных компонент лица, можно искать их в базе данных. \\

Eigenfaces в среднем работает хорошо, но PCA ищет оси, вдоль которых данные имеют наибольшую дисперсию.
Но мы решаем задачу классификации (каждый класс -- один человек, изображений одного лица в базе может быть много).
Нужно не пространство, вдоль которого данные наилучшим образом разделены, а то, где как можно лучше разнесены классы.
Для дискриминации между классами лиц можно использовать \textbf{LDA}.

LDA выбирает линейное подпространство, максимизирующие функцию от $ \Phi $ (здесь $ \Phi $ -- матрица, которую мы ищем; она задаст базис нового пространства, в которое мы перейдём).
Для этого максимизируем отношение межклассового разброса к внутриклассовому разбросу.

\end{document}
