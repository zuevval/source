\documentclass[main.tex]{subfiles}
\begin{document}

\section{Основные этапы построения машин опорных векторов}
5 апреля 2022 года

\subsection{Основные этапы проектирования}

\begin{enumerate}[noitemsep]
\item Предобработка исходных данных
\item Настройка машины
\begin{enumerate}[noitemsep]
	\item Выбор модели
	\item Выбор ядра
\end{enumerate}
\item Обучение
\item Тестирование

\end{enumerate}

В биоинформатике размеры выборки бывают небольшие, а размерность большая.

Подготовка (предобработка) исходных данных: отбор признаков (feature selection) и конструирование новых (feature extraction), очищение от шума (целесообразно перед FS/FE), масштабирование (стандартизация).

\subsection{Характеристики качества обучения}

performance measures / validation functions: чувствительность, специфичность и так далее.

ROC-анализ.
\begin{leftbar}
	Руководство по ROC-анализу: см. [1]
\end{leftbar}

\subsection{Стратегии формирования выборок при настройке машины опорных векторов}

Стратегия перевыбора -- resampling technique

\begin{enumerate}[noitemsep]
	\item hold-out (просто разделяем на train/test)
	\item k-fold cross-validation
	\item bootstrap (случайный выбор с возвращением)
	\item subsampling (случайный выбор без возвращения)
\end{enumerate}

Стратегия \emph{вложенного перевыбора}: качество модели оценивается по внешней тестовой выборке, а качество подобранных гиперпараметров в рамках одной модели -- по внутренней.

Вообще нет чёткого алгоритма создания успешного SVM-классификатора, но можно записать так:
<см. алгоритм со слайдов>

\subsection{Настройка машины опорных векторов}
Обычно - grid search (сперва грубая решётка, затем более мелкое разбиение).

Применение градиентных методов возможно, но затруднено из-за того, что связь функции цели с параметрами неявная.
Применяются также эволюционные методы на основе генетических алгоритмов.

Для оптимизации grid search используют поиск на квадродереве или латинском гиперкубе.

Асимптотическое поведение LOO-ошибки SVM-класссификатора (в задаче бинарной классификации) с гауссовским ядром: показано, что область подходящих значений имеет вполне определённую форму.


$\tilde C$ -- параметр регуляризации, который даёт наилучшее значение линейного классификатора.

Решение
\[ f_D: X \to R \]

Функция потерь
\[ L: R \times Y \to R, L = L(f(x), y) \equiv L(f, (x,y)) \]

Ожидаемый риск

\[ TODO \]

LOO-ошибка (в отличие от ожидаемого риска, почти не смешена):

\[ TODO \]

LOO-ошибка вычисляется длительное время.
Предложена верхняя граница LOO-ошибки стандартного SVM-классификатора:

\[ J_{err}^l = \frac{d}{l}, \quad d = \left\| \left\{ i: (\rho \alpha_i R^2_\Delta TODO) \right\} \right\| \]

Подобных верхних границ предложено много.

\subsection{Методы настройки, отличные от поиска на решётке}

\begin{enumerate}[noitemsep]
	\item Simulated annealing
	\item Стохастический метод поиска с чередущимися окрестностями (Variable Neighborhood Search)
	\item Метаалгоритм SPO (Sequential Parameter Optimization)
\end{enumerate}

\subsection{Примеры}

Splice - данные о границах сплайсинга нуклеотидных последовательностей

Данные  German (немецкий банк)

\begin{leftbar}
	Вначале в Splice 60 признаков, в German 24; с помощью простейшей фильтрации удалось избавиться от "шумящих" признаков, которые не вносят существенный вклад в решение.
	Это практически не улучшает (а иногда и ухудшает) результаты на тестовой выборке, но существенно ускоряет процесс тренировки.
\end{leftbar}

\section{Доклад Ани М}

% TODO начало пропущено, восстановить

Методы: нейросети, байесовские сети, цепи Маркова, дискриминантный анализ, метод опорных векторов. \\

Химические свойства нуклеотидов

\begin{tabular}{c|c c}
Chemical property & Acid & Class \\
\hline
Hydro % TODO
\end{tabular}

\[ x_i = \begin{cases}
	1 \quad if \quad s_i \in \{ A, G \} \\
	0 \quad if \quad s_j \in \{ C, T \} \\
\end{cases} \]

SVM (и другие ядерные методы) используется -- почему?

% В следующий раз?

\end{document}